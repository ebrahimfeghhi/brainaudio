{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc49bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: i woke up at 6 am and took the dog for a hike in the metacomet mountains we like to take morning adventures on the weekends\n",
      "Outputs:\n",
      "\tI woke up at 6 a.m. and took the dog for a hike in the Metacomet Mountains.\n",
      "\tWe like to take morning adventures on the weekends.\n",
      "\n",
      "Input: despite being mid march it snowed overnight and into the morning here in connecticut it was snowier up in the mountains than in the farmington valley where i live\n",
      "Outputs:\n",
      "\tDespite being mid March, it snowed overnight and into the morning.\n",
      "\tHere in Connecticut, it was snowier up in the mountains than in the Farmington Valley where I live.\n",
      "\n",
      "Input: when i got home i trained this model on the lambda cloud on an a100 gpu with about 10 million lines of text the total budget was less than 5 dollars\n",
      "Outputs:\n",
      "\tWhen I got home, I trained this model on the Lambda Cloud.\n",
      "\tOn an A100 GPU with about 10 million lines of text, the total budget was less than 5 dollars.\n",
      "\n",
      "Input: george hw bush was the president of the us for 8 years\n",
      "Outputs:\n",
      "\tGeorge H.W. Bush was the president of the U.S. for 8 years.\n",
      "\n",
      "Input: i saw mr smith at the store he was shopping for a new lawn mower i suggested he get one of those new battery operated ones they're so much quieter\n",
      "Outputs:\n",
      "\tI saw Mr. Smith at the store he was shopping for a new lawn mower.\n",
      "\tI suggested he get one of those new battery operated ones.\n",
      "\tThey're so much quieter.\n",
      "\n",
      "Input: i went to the fgw store and bought a new tg optical scope\n",
      "Outputs:\n",
      "\tI went to the FGW store and bought a new TG optical scope.\n",
      "\n",
      "Input: it's that man again itma was a radio comedy programme that was broadcast by the bbc for twelve series from 1939 to 1949 featuring tommy handley in the central role itma was a character driven comedy whose satirical targets included officialdom and the proliferation of minor wartime regulations parts of the scripts were rewritten in the hours before the broadcast to ensure topicality\n",
      "Outputs:\n",
      "\tIt's that man again.\n",
      "\tITMA was a radio comedy programme that was broadcast by the BBC for Twelve Series from 1939 to 1949, featuring Tommy Handley.\n",
      "\tIn the central role, ITMA was a character driven comedy whose satirical targets included officialdom and the proliferation of minor wartime regulations.\n",
      "\tParts of the scripts were rewritten in the hours before the broadcast to ensure topicality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from punctuators.models import PunctCapSegModelONNX\n",
    "\n",
    "# Instantiate this model\n",
    "# This will download the ONNX and SPE models. To clean up, delete this model from your HF cache directory.\n",
    "m = PunctCapSegModelONNX.from_pretrained(\"pcs_en\")\n",
    "\n",
    "# Define some input texts to punctuate\n",
    "input_texts: List[str] = [\n",
    "    # Literally my weekend\n",
    "    \"i woke up at 6 am and took the dog for a hike in the metacomet mountains we like to take morning adventures on the weekends\",\n",
    "    \"despite being mid march it snowed overnight and into the morning here in connecticut it was snowier up in the mountains than in the farmington valley where i live\",\n",
    "    \"when i got home i trained this model on the lambda cloud on an a100 gpu with about 10 million lines of text the total budget was less than 5 dollars\",\n",
    "    # Real acronyms in sentences that I made up\n",
    "    \"george hw bush was the president of the us for 8 years\",\n",
    "    \"i saw mr smith at the store he was shopping for a new lawn mower i suggested he get one of those new battery operated ones they're so much quieter\",\n",
    "    # See how the model performs on made-up acronyms \n",
    "    \"i went to the fgw store and bought a new tg optical scope\",\n",
    "    # First few sentences from today's featured article summary on wikipedia\n",
    "    \"it's that man again itma was a radio comedy programme that was broadcast by the bbc for twelve series from 1939 to 1949 featuring tommy handley in the central role itma was a character driven comedy whose satirical targets included officialdom and the proliferation of minor wartime regulations parts of the scripts were rewritten in the hours before the broadcast to ensure topicality\"\n",
    "]\n",
    "results: List[List[str]] = m.infer(input_texts)\n",
    "for input_text, output_texts in zip(input_texts, results):\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Outputs:\")\n",
    "    for text in output_texts:\n",
    "        print(f\"\\t{text}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6692fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "transcripts = pd.read_pickle(\"/data2/brain2text/b2t_25/transcripts_val_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Get all sentences from transcripts\n",
    "sentences = transcripts.tolist() if hasattr(transcripts, 'tolist') else list(transcripts)\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "\n",
    "# Check initial VRAM\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    initial_mem = torch.cuda.memory_allocated() / 1024**3\n",
    "    print(f\"Initial VRAM: {initial_mem:.2f} GB\")\n",
    "\n",
    "# Process in batches of 500\n",
    "batch_size = 500\n",
    "all_results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0, len(sentences), batch_size):\n",
    "    batch = sentences[i:i+batch_size]\n",
    "    batch_results = m.infer(batch)\n",
    "    all_results.extend(batch_results)\n",
    "    \n",
    "    # Print progress\n",
    "    processed = min(i + batch_size, len(sentences))\n",
    "    elapsed = time.time() - start_time\n",
    "    rate = processed / elapsed\n",
    "    print(f\"Processed {processed}/{len(sentences)} sentences ({rate:.1f} sent/sec)\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        current_mem = torch.cuda.memory_allocated() / 1024**3\n",
    "        peak_mem = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        print(f\"  Current VRAM: {current_mem:.2f} GB, Peak VRAM: {peak_mem:.2f} GB\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total time: {total_time:.2f} seconds\")\n",
    "print(f\"Average speed: {len(sentences)/total_time:.1f} sentences/sec\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Peak VRAM used: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
