{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb2077b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Union, Optional, Any\n",
    "import json\n",
    "\n",
    "def compare_model_args(\n",
    "    model_paths: List[Union[str, Path]],\n",
    "    keys_to_compare: Optional[List[str]] = None,\n",
    "    keys_to_ignore: Optional[List[str]] = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Load and compare arguments across multiple model checkpoints.\n",
    "    \n",
    "    Args:\n",
    "        model_paths: List of paths to model directories (each should contain 'args' file)\n",
    "        keys_to_compare: Optional list of specific keys to compare. If None, shows all keys.\n",
    "        keys_to_ignore: Optional list of keys to skip. Default ignores common noisy keys.\n",
    "    \"\"\"\n",
    "    # Default keys to ignore\n",
    "    if keys_to_ignore is None:\n",
    "        keys_to_ignore = ['wandb', 'participant_suffixes', 'interctc', \n",
    "                         'manifest_paths', 'milestones', 'outputDir']\n",
    "    \n",
    "    # Load args from each model\n",
    "    model_args = []\n",
    "    valid_paths = []\n",
    "    \n",
    "    for model_path in model_paths:\n",
    "        path = Path(model_path)\n",
    "        args_file = path / \"args\"\n",
    "        \n",
    "        if not args_file.exists():\n",
    "            print(f\"Warning: {args_file} does not exist, skipping.\")\n",
    "            continue\n",
    "            \n",
    "        with open(args_file, \"rb\") as f:\n",
    "            args = pickle.load(f)\n",
    "            model_args.append(args)\n",
    "            valid_paths.append(path.name)\n",
    "    \n",
    "    if not model_args:\n",
    "        print(\"No valid model args found.\")\n",
    "        return\n",
    "    \n",
    "    # Collect all keys if not specified\n",
    "    if keys_to_compare is None:\n",
    "        all_keys = set()\n",
    "        for args in model_args:\n",
    "            # Handle both dict and object with __dict__\n",
    "            if isinstance(args, dict):\n",
    "                all_keys.update(args.keys())\n",
    "            else:\n",
    "                all_keys.update(vars(args).keys())\n",
    "        # Filter out ignored keys\n",
    "        all_keys = all_keys - set(keys_to_ignore)\n",
    "        keys_to_compare = sorted(all_keys)\n",
    "    \n",
    "    def format_transformer_specs(transformer_dict: dict) -> str:\n",
    "        \"\"\"Format transformer specs in a clean, readable way.\"\"\"\n",
    "        lines = []\n",
    "        for key, value in sorted(transformer_dict.items()):\n",
    "            if isinstance(value, dict):\n",
    "                # Nested dict (like chunked_attention)\n",
    "                lines.append(f\"{key}:\")\n",
    "                for k, v in sorted(value.items()):\n",
    "                    if isinstance(v, dict):\n",
    "                        lines.append(f\"  {k}:\")\n",
    "                        for kk, vv in sorted(v.items()):\n",
    "                            lines.append(f\"    {kk}: {vv}\")\n",
    "                    else:\n",
    "                        lines.append(f\"  {k}: {v}\")\n",
    "            elif isinstance(value, float):\n",
    "                if abs(value) < 0.001 or abs(value) > 10000:\n",
    "                    lines.append(f\"{key}: {value:.2e}\")\n",
    "                else:\n",
    "                    lines.append(f\"{key}: {value:.4f}\")\n",
    "            else:\n",
    "                lines.append(f\"{key}: {value}\")\n",
    "        return \"\\n  \" + \"\\n  \".join(lines)\n",
    "    \n",
    "    def format_value(value: Any, key: str = \"\", max_width: int = 50) -> str:\n",
    "        \"\"\"Format value for display with pretty printing for nested structures.\"\"\"\n",
    "        # Handle numeric types with appropriate precision\n",
    "        if isinstance(value, float):\n",
    "            if abs(value) < 0.001 or abs(value) > 10000:\n",
    "                return f\"{value:.2e}\"\n",
    "            else:\n",
    "                return f\"{value:.4f}\"\n",
    "        \n",
    "        # Special handling for model dict - filter out GRU, format transformer nicely\n",
    "        if key == \"model\" and isinstance(value, dict):\n",
    "            filtered_model = {k: v for k, v in value.items() if k != 'gru'}\n",
    "            if 'transformer' in filtered_model:\n",
    "                lines = []\n",
    "                for model_key, model_val in filtered_model.items():\n",
    "                    if model_key == 'transformer':\n",
    "                        lines.append(f\"transformer:{format_transformer_specs(model_val)}\")\n",
    "                    else:\n",
    "                        lines.append(f\"{model_key}: {model_val}\")\n",
    "                return \"\\n  \" + \"\\n  \".join(lines)\n",
    "            return json.dumps(filtered_model, indent=2).replace(\"\\n\", \"\\n  \")\n",
    "        \n",
    "        # Pretty print dicts on multiple lines if they're nested\n",
    "        if isinstance(value, dict):\n",
    "            # For model specs and nested dicts, format nicely\n",
    "            if len(str(value)) > max_width:\n",
    "                formatted = json.dumps(value, indent=2)\n",
    "                return \"\\n  \" + formatted.replace(\"\\n\", \"\\n  \")\n",
    "            return str(value)\n",
    "        \n",
    "        # Convert to string and truncate if needed\n",
    "        value_str = str(value)\n",
    "        if len(value_str) > max_width:\n",
    "            return value_str[:max_width-3] + \"...\"\n",
    "        return value_str\n",
    "    \n",
    "    # Print comparison\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Comparing {len(valid_paths)} models:\")\n",
    "    for i, name in enumerate(valid_paths, 1):\n",
    "        print(f\"  [{i}] {name}\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    # Group related keys\n",
    "    masking_keys = ['max_mask_pct', 'num_masks']\n",
    "    \n",
    "    # Find differences and group masking params\n",
    "    differences = []\n",
    "    same = []\n",
    "    masking_values = {k: [] for k in masking_keys}\n",
    "    \n",
    "    for key in keys_to_compare:\n",
    "        values = []\n",
    "        for args in model_args:\n",
    "            # Handle both dict and object access\n",
    "            if isinstance(args, dict):\n",
    "                value = args.get(key, \"N/A\")\n",
    "            else:\n",
    "                value = getattr(args, key, \"N/A\")\n",
    "            values.append(value)\n",
    "        \n",
    "        # Track masking params separately\n",
    "        if key in masking_keys:\n",
    "            masking_values[key] = values\n",
    "            continue\n",
    "        \n",
    "        # Check if all values are the same\n",
    "        if len(set(str(v) for v in values)) == 1:\n",
    "            same.append(key)\n",
    "        else:\n",
    "            differences.append((key, values))\n",
    "    \n",
    "    # Add masking params as a group if there are differences\n",
    "    masking_differs = any(\n",
    "        len(set(str(v) for v in masking_values[k])) > 1 \n",
    "        for k in masking_keys if masking_values[k]\n",
    "    )\n",
    "    if masking_differs:\n",
    "        differences.insert(0, ('masking_params', masking_values))\n",
    "    \n",
    "    # Print differences first (most important)\n",
    "    if differences:\n",
    "        print(f\"\\n{'DIFFERENCES':-^100}\\n\")\n",
    "        for key, values in differences:\n",
    "            print(f\"\\n{key}:\")\n",
    "            print(\"-\" * 100)\n",
    "            \n",
    "            # Special handling for grouped masking params\n",
    "            if key == 'masking_params':\n",
    "                for idx, name in enumerate(valid_paths):\n",
    "                    mask_info = \", \".join(f\"{k}={masking_values[k][idx]}\" for k in masking_keys if masking_values[k])\n",
    "                    print(f\"  [{idx+1}] {name:<40} = {mask_info}\")\n",
    "                continue\n",
    "            \n",
    "            for i, (name, value) in enumerate(zip(valid_paths, values), 1):\n",
    "                formatted_val = format_value(value, key=key)\n",
    "                if \"\\n\" in formatted_val:\n",
    "                    print(f\"  [{i}] {name}:{formatted_val}\")\n",
    "                else:\n",
    "                    print(f\"  [{i}] {name:<40} = {formatted_val}\")\n",
    "    \n",
    "    # Print same values (less important, collapsed)\n",
    "    if same:\n",
    "        print(f\"\\n\\n{'SAME VALUES (collapsed)':-^100}\\n\")\n",
    "        for key in same:\n",
    "            value = model_args[0].get(key) if isinstance(model_args[0], dict) else getattr(model_args[0], key)\n",
    "            formatted = format_value(value, key=key, max_width=80)\n",
    "            if \"\\n\" in formatted:\n",
    "                print(f\"\\n{key}:{formatted}\")\n",
    "            else:\n",
    "                print(f\"{key:<40} = {formatted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7291551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "Comparing 4 models:\n",
      "  [1] baseline_hpo_combined_trial_44\n",
      "  [2] baseline_hpo_combined_trial_12\n",
      "  [3] baseline_hpo_combined_trial_6\n",
      "  [4] baseline_hpo_combined_trial_22\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "--------------------------------------------DIFFERENCES---------------------------------------------\n",
      "\n",
      "\n",
      "masking_params:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = max_mask_pct=0.055, num_masks=12\n",
      "  [2] baseline_hpo_combined_trial_12           = max_mask_pct=0.023, num_masks=26\n",
      "  [3] baseline_hpo_combined_trial_6            = max_mask_pct=0.024, num_masks=29\n",
      "  [4] baseline_hpo_combined_trial_22           = max_mask_pct=0.068, num_masks=8\n",
      "\n",
      "constantOffsetSD:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = 0.0953\n",
      "  [2] baseline_hpo_combined_trial_12           = 0.0813\n",
      "  [3] baseline_hpo_combined_trial_6            = 0.0875\n",
      "  [4] baseline_hpo_combined_trial_22           = 0.0656\n",
      "\n",
      "dropout:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = 0.2547\n",
      "  [2] baseline_hpo_combined_trial_12           = 0.1562\n",
      "  [3] baseline_hpo_combined_trial_6            = 0.1375\n",
      "  [4] baseline_hpo_combined_trial_22           = 0.2031\n",
      "\n",
      "l2_decay:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = 4.53e-05\n",
      "  [2] baseline_hpo_combined_trial_12           = 1.33e-05\n",
      "  [3] baseline_hpo_combined_trial_6            = 5.62e-05\n",
      "  [4] baseline_hpo_combined_trial_22           = 1.54e-05\n",
      "\n",
      "learning_rate:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = 0.0017\n",
      "  [2] baseline_hpo_combined_trial_12           = 0.0016\n",
      "  [3] baseline_hpo_combined_trial_6            = 0.0027\n",
      "  [4] baseline_hpo_combined_trial_22           = 0.0029\n",
      "\n",
      "learning_rate_min:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = 1.71e-04\n",
      "  [2] baseline_hpo_combined_trial_12           = 1.59e-04\n",
      "  [3] baseline_hpo_combined_trial_6            = 2.69e-04\n",
      "  [4] baseline_hpo_combined_trial_22           = 2.92e-04\n",
      "\n",
      "model:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44:\n",
      "  transformer:\n",
      "  chunked_attention:\n",
      "    chunk_size_max: 20\n",
      "    chunk_size_min: 1\n",
      "    chunkwise_prob: 0.51875\n",
      "    context_sec_max: 20\n",
      "    context_sec_min: 20\n",
      "    eval:\n",
      "      chunk_size: 5\n",
      "      context_chunks: 50\n",
      "    left_constrain_prob: 1.0\n",
      "    timestep_duration_sec: 0.08\n",
      "  d_model: 448\n",
      "  depth: 5\n",
      "  dim_head: 64\n",
      "  features_list: [512, 256]\n",
      "  mlp_dim_ratio: 4\n",
      "  n_heads: 7\n",
      "  name: Transformer\n",
      "  samples_per_patch: 4\n",
      "  [2] baseline_hpo_combined_trial_12:\n",
      "  transformer:\n",
      "  chunked_attention:\n",
      "    chunk_size_max: 20\n",
      "    chunk_size_min: 1\n",
      "    chunkwise_prob: 0.675\n",
      "    context_sec_max: 20\n",
      "    context_sec_min: 20\n",
      "    eval:\n",
      "      chunk_size: 5\n",
      "      context_chunks: 50\n",
      "    left_constrain_prob: 1.0\n",
      "    timestep_duration_sec: 0.08\n",
      "  d_model: 392\n",
      "  depth: 7\n",
      "  dim_head: 49\n",
      "  features_list: [512, 256]\n",
      "  mlp_dim_ratio: 4\n",
      "  n_heads: 8\n",
      "  name: Transformer\n",
      "  samples_per_patch: 4\n",
      "  [3] baseline_hpo_combined_trial_6:\n",
      "  transformer:\n",
      "  chunked_attention:\n",
      "    chunk_size_max: 20\n",
      "    chunk_size_min: 1\n",
      "    chunkwise_prob: 0.55\n",
      "    context_sec_max: 20\n",
      "    context_sec_min: 20\n",
      "    eval:\n",
      "      chunk_size: 5\n",
      "      context_chunks: 50\n",
      "    left_constrain_prob: 1.0\n",
      "    timestep_duration_sec: 0.08\n",
      "  d_model: 522\n",
      "  depth: 6\n",
      "  dim_head: 58\n",
      "  features_list: [512, 256]\n",
      "  mlp_dim_ratio: 4\n",
      "  n_heads: 9\n",
      "  name: Transformer\n",
      "  samples_per_patch: 4\n",
      "  [4] baseline_hpo_combined_trial_22:\n",
      "  transformer:\n",
      "  chunked_attention:\n",
      "    chunk_size_max: 20\n",
      "    chunk_size_min: 1\n",
      "    chunkwise_prob: 0.4375\n",
      "    context_sec_max: 20\n",
      "    context_sec_min: 20\n",
      "    eval:\n",
      "      chunk_size: 5\n",
      "      context_chunks: 50\n",
      "    left_constrain_prob: 1.0\n",
      "    timestep_duration_sec: 0.08\n",
      "  d_model: 371\n",
      "  depth: 7\n",
      "  dim_head: 53\n",
      "  features_list: [512, 256]\n",
      "  mlp_dim_ratio: 4\n",
      "  n_heads: 7\n",
      "  name: Transformer\n",
      "  samples_per_patch: 4\n",
      "\n",
      "modelName:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = baseline_hpo_combined_trial_44\n",
      "  [2] baseline_hpo_combined_trial_12           = baseline_hpo_combined_trial_12\n",
      "  [3] baseline_hpo_combined_trial_6            = baseline_hpo_combined_trial_6\n",
      "  [4] baseline_hpo_combined_trial_22           = baseline_hpo_combined_trial_22\n",
      "\n",
      "whiteNoiseSD:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  [1] baseline_hpo_combined_trial_44           = 0.1469\n",
      "  [2] baseline_hpo_combined_trial_12           = 0.2375\n",
      "  [3] baseline_hpo_combined_trial_6            = 0.1750\n",
      "  [4] baseline_hpo_combined_trial_22           = 0.2562\n",
      "\n",
      "\n",
      "--------------------------------------SAME VALUES (collapsed)---------------------------------------\n",
      "\n",
      "acoustic_scale                           = 0.6000\n",
      "batchSize                                = 64\n",
      "beam_size                                = 30\n",
      "beta1                                    = 0.9000\n",
      "beta2                                    = 0.9990\n",
      "device                                   = cuda:0\n",
      "early_stopping_checkpoint                = 100\n",
      "early_stopping_enabled                   = True\n",
      "early_stopping_no_improvement            = 15\n",
      "early_stopping_wer_threshold             = 0.1600\n",
      "eps                                      = 1.00e-08\n",
      "evaluate_every_n_epochs                  = 5\n",
      "evaluate_wer                             = True\n",
      "gamma                                    = None\n",
      "gaussianSmoothWidth                      = 2.0000\n",
      "grad_norm_clip_value                     = 10\n",
      "input_dropout                            = 0.1000\n",
      "learning_rate_decay_steps                = 340\n",
      "learning_rate_warmup_steps               = 10\n",
      "learning_scheduler                       = cosine\n",
      "lm_weight                                = 2.0000\n",
      "load_pretrained_model                    = \n",
      "lr_scaling_factor                        = 0.1000\n",
      "modelType                                = transformer\n",
      "nClasses                                 = 40\n",
      "n_epochs                                 = 350\n",
      "optimizer                                = AdamW\n",
      "random_cut                               = 0\n",
      "seed                                     = 0\n",
      "seeds                                    = [0]\n",
      "smooth_kernel_size                       = 20\n",
      "use_amp                                  = True\n",
      "word_score                               = 0.1000\n"
     ]
    }
   ],
   "source": [
    "compare_model_args([\n",
    "    \"/data2/brain2text/b2t_combined/outputs/baseline_hpo_combined_trial_44\",\n",
    "    \"/data2/brain2text/b2t_combined/outputs/baseline_hpo_combined_trial_12\", \n",
    "    \"/data2/brain2text/b2t_combined/outputs/baseline_hpo_combined_trial_6\",\n",
    "    \"/data2/brain2text/b2t_combined/outputs/baseline_hpo_combined_trial_22\"\n",
    "], keys_to_compare=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0680d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
