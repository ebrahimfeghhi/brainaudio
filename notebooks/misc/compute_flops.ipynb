{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim/brainaudio/.venv/lib/python3.12/site-packages/torchtnt/utils/version.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/home3/ebrahim/brainaudio/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchtnt.utils.flops import FlopTensorDispatchMode\n",
    "from torch import nn     \n",
    "import torch\n",
    "import copy\n",
    "from brainaudio.models.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_dim = 256\n",
    "kernel_len = 32\n",
    "layer_dim = 5\n",
    "hidden_dim = 1024\n",
    "\n",
    "tf_hidden_dim = 384\n",
    "tf_layers = 5\n",
    "tf_num_heads = 6\n",
    "tf_head_size = 64\n",
    "tf_mlp_dim_ratio = 4\n",
    "tf_dropout = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_decoder = nn.GRU(\n",
    "            (neural_dim) * kernel_len,\n",
    "            hidden_dim,\n",
    "            layer_dim,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "fc_decoder_out = nn.Linear(hidden_dim, 40 + 1) \n",
    "\n",
    "\n",
    "gru_decoder_bidirectional = nn.GRU(\n",
    "            (neural_dim) * kernel_len,\n",
    "            hidden_dim,\n",
    "            layer_dim,\n",
    "            batch_first=True,\n",
    "            dropout=0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "fc_decoder_out_bi = nn.Linear(hidden_dim*2, 40 + 1) \n",
    "\n",
    "\n",
    "tf_model = Transformer(384, 5, 6, 64, 4, \n",
    "                                    0, use_relative_bias=True)\n",
    "\n",
    "\n",
    "fc_decoder_out = nn.Linear(hidden_dim, 40 + 1) \n",
    "\n",
    "fc_decoder_out_2 = nn.Linear(384, 40 + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1,500,256) # 10 seconds of input, each bin is 20 ms, 20 ms * 500 = 10 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 32,768,000\n",
      "≈ 3.28 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "daySpecific = nn.Linear(256, 256)\n",
    "with FlopTensorDispatchMode(daySpecific) as ftdm:\n",
    "    res = daySpecific(inputs)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")     \n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 118, 8192])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checking the shape after strided inputs \n",
    "should be ((X_len - kernel_len) / strideLen) + 1\n",
    "((500 - 32) / 4) + 1 = 118.\n",
    "\"\"\"\n",
    "unfolder = torch.nn.Unfold(\n",
    "            (kernel_len, 1), dilation=1, padding=0, stride=4\n",
    "        )\n",
    "stridedInputs = torch.permute(\n",
    "            unfolder(\n",
    "                torch.unsqueeze(torch.permute(inputs, (0, 2, 1)), 3)\n",
    "            ),\n",
    "            (0, 2, 1),\n",
    "        )\n",
    "stridedInputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 6,310,330,368\n",
      "≈ 631.03 MFLOPs\n",
      "Total forward FLOPs: 4,954,112\n",
      "≈ 0.50 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "stridedInputs = torch.randn(1,118, neural_dim*kernel_len)\n",
    "with FlopTensorDispatchMode(gru_decoder) as ftdm:\n",
    "    res_gru, _ = gru_decoder(stridedInputs)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs\n",
    "\n",
    "with FlopTensorDispatchMode(fc_decoder_out) as ftdm:\n",
    "    res2 = fc_decoder_out(res_gru)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 15,590,227,968\n",
      "≈ 1559.02 MFLOPs\n",
      "Total forward FLOPs: 9,908,224\n",
      "≈ 0.99 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "stridedInputs = torch.randn(1,118, neural_dim*kernel_len)\n",
    "with FlopTensorDispatchMode(gru_decoder) as ftdm:\n",
    "    res_gru, _ = gru_decoder_bidirectional(stridedInputs)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs\n",
    "\n",
    "with FlopTensorDispatchMode(fc_decoder_out_bi) as ftdm:\n",
    "    res2 = fc_decoder_out_bi(res_gru)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFLOPS FOR UNDIRECTIONAL GRU: 634.81\n"
     ]
    }
   ],
   "source": [
    "print(f\"MFLOPS FOR UNDIRECTIONAL GRU: {631.03 + 0.50 + 3.28}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFLOPS FOR BIDIRECTIONAL GRU: 1563.29\n"
     ]
    }
   ],
   "source": [
    "print(f\"MFLOPS FOR BIDIRECTIONAL GRU: {1559.02  + 0.99 + 3.28}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 245,760,000\n",
      "≈ 24.58 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "tf_inputs = torch.randn(1,500,256*5)\n",
    "patch_transform = nn.Linear(256*5, 384)\n",
    "with FlopTensorDispatchMode(patch_transform) as ftdm:\n",
    "    patched_inputs = patch_transform(tf_inputs)\n",
    "    #seq_out = fc_decoder_out_2(res)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total forward FLOPs: 3,394,560,000\n",
      "≈ 339.46 MFLOPs\n"
     ]
    }
   ],
   "source": [
    "tf_inputs = torch.randn(1,100,384)\n",
    "model = Transformer(384, 5, 6, 64, 4)\n",
    "\n",
    "with FlopTensorDispatchMode(model) as ftdm:\n",
    "    res = model(tf_inputs)\n",
    "    #seq_out = fc_decoder_out_2(res)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with FlopTensorDispatchMode(fc_decoder_out_2) as ftdm:\n",
    "    res2 = fc_decoder_out_2(res)\n",
    "    #seq_out = fc_decoder_out(res)\n",
    "    flops_forward = copy.deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    \n",
    "total_flops = sum(                # outer sum\n",
    "    sum(inner.values())           #  ← inner sum\n",
    "    for inner in flops_forward.values()\n",
    ")\n",
    "\n",
    "print(f\"Total forward FLOPs: {total_flops:,}\")        # e.g. 53,502,976\n",
    "print(f\"≈ {total_flops/1e6/10:.2f} MFLOPs\")              # or /1e9 for GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
