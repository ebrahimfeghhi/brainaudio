{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagineville_vocab_file = \"/data2/brain2text/lm/vocab_lower_100k.txt\"\n",
    "g2p = G2p()\n",
    "\n",
    "with open (imagineville_vocab_file, mode=\"r\") as f:\n",
    "    \n",
    "    imagineville_vocab = f.readlines()\n",
    "    \n",
    "lexicon_imagineville_dict = {}\n",
    "\n",
    "for idx, word_txt in enumerate(imagineville_vocab):\n",
    "    lexicon_imagineville_dict[word_txt.strip()] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': 0,\n",
       " '</s>': 1,\n",
       " '.period': 2,\n",
       " 'the': 3,\n",
       " ',comma': 4,\n",
       " 'to': 5,\n",
       " 'and': 6,\n",
       " 'a': 7,\n",
       " 'i': 8,\n",
       " 'of': 9,\n",
       " 'in': 10,\n",
       " 'is': 11,\n",
       " 'it': 12,\n",
       " 'you': 13,\n",
       " 'that': 14,\n",
       " 'for': 15,\n",
       " 'this': 16,\n",
       " '!exclamation-point': 17,\n",
       " '?question-mark': 18,\n",
       " 'on': 19,\n",
       " 'was': 20,\n",
       " 'with': 21,\n",
       " 'be': 22,\n",
       " 'have': 23,\n",
       " 'my': 24,\n",
       " 'not': 25,\n",
       " 'but': 26,\n",
       " 'are': 27,\n",
       " 'as': 28,\n",
       " 'so': 29,\n",
       " 'we': 30,\n",
       " 'if': 31,\n",
       " 'he': 32,\n",
       " 'they': 33,\n",
       " 'at': 34,\n",
       " 'all': 35,\n",
       " 'me': 36,\n",
       " 'your': 37,\n",
       " 'will': 38,\n",
       " 'or': 39,\n",
       " 'can': 40,\n",
       " 'just': 41,\n",
       " 'from': 42,\n",
       " 'what': 43,\n",
       " 'do': 44,\n",
       " 'one': 45,\n",
       " 'like': 46,\n",
       " 'an': 47,\n",
       " 'by': 48,\n",
       " 'his': 49,\n",
       " 'there': 50,\n",
       " 'out': 51,\n",
       " 'had': 52,\n",
       " 'would': 53,\n",
       " 'up': 54,\n",
       " 'when': 55,\n",
       " 'about': 56,\n",
       " 'get': 57,\n",
       " 'no': 58,\n",
       " \"it's\": 59,\n",
       " 'has': 60,\n",
       " \"i'm\": 61,\n",
       " 'more': 62,\n",
       " 'some': 63,\n",
       " \"don't\": 64,\n",
       " 'time': 65,\n",
       " 'her': 66,\n",
       " 'them': 67,\n",
       " 'were': 68,\n",
       " 'good': 69,\n",
       " 'how': 70,\n",
       " 'their': 71,\n",
       " 'she': 72,\n",
       " 'know': 73,\n",
       " 'been': 74,\n",
       " 'who': 75,\n",
       " 'now': 76,\n",
       " 'which': 77,\n",
       " 'very': 78,\n",
       " 'any': 79,\n",
       " 'think': 80,\n",
       " 'also': 81,\n",
       " 'then': 82,\n",
       " 'other': 83,\n",
       " 'our': 84,\n",
       " 'only': 85,\n",
       " 'people': 86,\n",
       " 'go': 87,\n",
       " 'him': 88,\n",
       " 'see': 89,\n",
       " 'well': 90,\n",
       " 'great': 91,\n",
       " 'here': 92,\n",
       " 'really': 93,\n",
       " 'could': 94,\n",
       " 'back': 95,\n",
       " 'should': 96,\n",
       " 'because': 97,\n",
       " 'new': 98,\n",
       " 'make': 99,\n",
       " 'much': 100,\n",
       " 'want': 101,\n",
       " 'than': 102,\n",
       " 'way': 103,\n",
       " 'did': 104,\n",
       " 'too': 105,\n",
       " 'even': 106,\n",
       " 'into': 107,\n",
       " 'need': 108,\n",
       " 'am': 109,\n",
       " 'love': 110,\n",
       " 'these': 111,\n",
       " 'work': 112,\n",
       " 'after': 113,\n",
       " 'its': 114,\n",
       " 'got': 115,\n",
       " 'first': 116,\n",
       " 'going': 117,\n",
       " 'right': 118,\n",
       " 'still': 119,\n",
       " 'us': 120,\n",
       " 'use': 121,\n",
       " 'over': 122,\n",
       " 'day': 123,\n",
       " 'why': 124,\n",
       " 'where': 125,\n",
       " 'never': 126,\n",
       " 'before': 127,\n",
       " 'said': 128,\n",
       " 'two': 129,\n",
       " 'take': 130,\n",
       " 'many': 131,\n",
       " 'off': 132,\n",
       " 'may': 133,\n",
       " 'being': 134,\n",
       " 'most': 135,\n",
       " 'does': 136,\n",
       " 'little': 137,\n",
       " \"can't\": 138,\n",
       " 'down': 139,\n",
       " \"i've\": 140,\n",
       " 'something': 141,\n",
       " 'come': 142,\n",
       " 'say': 143,\n",
       " 'made': 144,\n",
       " 'better': 145,\n",
       " \"that's\": 146,\n",
       " 'again': 147,\n",
       " 'place': 148,\n",
       " 'those': 149,\n",
       " 'same': 150,\n",
       " 'life': 151,\n",
       " 'best': 152,\n",
       " 'look': 153,\n",
       " \"you're\": 154,\n",
       " 'find': 155,\n",
       " 'while': 156,\n",
       " 'sure': 157,\n",
       " 'always': 158,\n",
       " \"didn't\": 159,\n",
       " 'last': 160,\n",
       " 'through': 161,\n",
       " 'help': 162,\n",
       " 'things': 163,\n",
       " 'such': 164,\n",
       " 'another': 165,\n",
       " 'long': 166,\n",
       " 'thing': 167,\n",
       " 'every': 168,\n",
       " 'please': 169,\n",
       " 'try': 170,\n",
       " 'today': 171,\n",
       " 'used': 172,\n",
       " 'few': 173,\n",
       " 'home': 174,\n",
       " \"i'll\": 175,\n",
       " 'around': 176,\n",
       " 'book': 177,\n",
       " 'feel': 178,\n",
       " 'give': 179,\n",
       " 'though': 180,\n",
       " 'without': 181,\n",
       " 'might': 182,\n",
       " 'both': 183,\n",
       " 'man': 184,\n",
       " 'own': 185,\n",
       " 'lot': 186,\n",
       " 'put': 187,\n",
       " 'ever': 188,\n",
       " 'since': 189,\n",
       " \"doesn't\": 190,\n",
       " 'let': 191,\n",
       " 'next': 192,\n",
       " 'food': 193,\n",
       " 'keep': 194,\n",
       " 'thanks': 195,\n",
       " 'done': 196,\n",
       " 'read': 197,\n",
       " 'someone': 198,\n",
       " 'anything': 199,\n",
       " 'night': 200,\n",
       " 'must': 201,\n",
       " 'nice': 202,\n",
       " 'world': 203,\n",
       " 'service': 204,\n",
       " 'getting': 205,\n",
       " 'found': 206,\n",
       " 'problem': 207,\n",
       " 'thought': 208,\n",
       " 'different': 209,\n",
       " 'tell': 210,\n",
       " 'nothing': 211,\n",
       " 'pretty': 212,\n",
       " 'bad': 213,\n",
       " 'using': 214,\n",
       " 'anyone': 215,\n",
       " 'looking': 216,\n",
       " 'doing': 217,\n",
       " 'enough': 218,\n",
       " 'however': 219,\n",
       " 'everything': 220,\n",
       " 'away': 221,\n",
       " 'each': 222,\n",
       " 'having': 223,\n",
       " 'once': 224,\n",
       " 'part': 225,\n",
       " 'went': 226,\n",
       " 'year': 227,\n",
       " 'actually': 228,\n",
       " 'came': 229,\n",
       " 'years': 230,\n",
       " 'big': 231,\n",
       " 'change': 232,\n",
       " 'case': 233,\n",
       " 'game': 234,\n",
       " 'point': 235,\n",
       " 'end': 236,\n",
       " 'yet': 237,\n",
       " 'happy': 238,\n",
       " 'already': 239,\n",
       " 'god': 240,\n",
       " 'hope': 241,\n",
       " 'old': 242,\n",
       " 'trying': 243,\n",
       " 'money': 244,\n",
       " 'maybe': 245,\n",
       " 'oh': 246,\n",
       " 'free': 247,\n",
       " 'set': 248,\n",
       " 'far': 249,\n",
       " 'hard': 250,\n",
       " 'until': 251,\n",
       " 'show': 252,\n",
       " 'thank': 253,\n",
       " 'house': 254,\n",
       " 'family': 255,\n",
       " 'start': 256,\n",
       " 'bit': 257,\n",
       " 'able': 258,\n",
       " 'yes': 259,\n",
       " 'everyone': 260,\n",
       " 'seems': 261,\n",
       " 'believe': 262,\n",
       " 'makes': 263,\n",
       " \"he's\": 264,\n",
       " 'between': 265,\n",
       " 'left': 266,\n",
       " 'order': 267,\n",
       " 'friends': 268,\n",
       " \"isn't\": 269,\n",
       " 'information': 270,\n",
       " 'probably': 271,\n",
       " 'real': 272,\n",
       " \"there's\": 273,\n",
       " \"won't\": 274,\n",
       " 'wait': 275,\n",
       " 'name': 276,\n",
       " 'times': 277,\n",
       " 'call': 278,\n",
       " \"i'd\": 279,\n",
       " 'against': 280,\n",
       " 'week': 281,\n",
       " 'school': 282,\n",
       " 'under': 283,\n",
       " 'else': 284,\n",
       " 'working': 285,\n",
       " 'three': 286,\n",
       " 'article': 287,\n",
       " 'phone': 288,\n",
       " 'mean': 289,\n",
       " 'care': 290,\n",
       " 'issue': 291,\n",
       " 'play': 292,\n",
       " 'took': 293,\n",
       " 'wrong': 294,\n",
       " 'job': 295,\n",
       " 'kind': 296,\n",
       " 'told': 297,\n",
       " 'small': 298,\n",
       " 'days': 299,\n",
       " 'person': 300,\n",
       " 'side': 301,\n",
       " 'looks': 302,\n",
       " 'high': 303,\n",
       " 'wanted': 304,\n",
       " 'making': 305,\n",
       " 'stop': 306,\n",
       " 'check': 307,\n",
       " 'run': 308,\n",
       " 'page': 309,\n",
       " 'easy': 310,\n",
       " 'talk': 311,\n",
       " 'open': 312,\n",
       " 'live': 313,\n",
       " 'u': 314,\n",
       " 'seen': 315,\n",
       " 'car': 316,\n",
       " 'during': 317,\n",
       " 'works': 318,\n",
       " 'full': 319,\n",
       " 'either': 320,\n",
       " 'tried': 321,\n",
       " 'whole': 322,\n",
       " 'others': 323,\n",
       " 'fun': 324,\n",
       " 'story': 325,\n",
       " 'mind': 326,\n",
       " 'understand': 327,\n",
       " 'second': 328,\n",
       " 'least': 329,\n",
       " 'gonna': 330,\n",
       " 'reason': 331,\n",
       " 'quite': 332,\n",
       " 'idea': 333,\n",
       " 'experience': 334,\n",
       " 'course': 335,\n",
       " 'post': 336,\n",
       " 'later': 337,\n",
       " 'soon': 338,\n",
       " 'yeah': 339,\n",
       " 'almost': 340,\n",
       " 'head': 341,\n",
       " 'state': 342,\n",
       " 'room': 343,\n",
       " 'myself': 344,\n",
       " 'fact': 345,\n",
       " 'called': 346,\n",
       " 'support': 347,\n",
       " \"wasn't\": 348,\n",
       " 'coming': 349,\n",
       " 'needs': 350,\n",
       " 'buy': 351,\n",
       " 'number': 352,\n",
       " 'definitely': 353,\n",
       " 'fine': 354,\n",
       " 'amazing': 355,\n",
       " 'together': 356,\n",
       " 'possible': 357,\n",
       " 'ask': 358,\n",
       " 'system': 359,\n",
       " 'morning': 360,\n",
       " 'business': 361,\n",
       " 'guys': 362,\n",
       " 'wish': 363,\n",
       " 'sorry': 364,\n",
       " 'add': 365,\n",
       " 'water': 366,\n",
       " 'less': 367,\n",
       " 'guess': 368,\n",
       " 'leave': 369,\n",
       " 'rather': 370,\n",
       " 'friend': 371,\n",
       " 'instead': 372,\n",
       " \"they're\": 373,\n",
       " 'true': 374,\n",
       " 'top': 375,\n",
       " 'hand': 376,\n",
       " 'data': 377,\n",
       " 'saw': 378,\n",
       " 'started': 379,\n",
       " 'several': 380,\n",
       " 'face': 381,\n",
       " 'list': 382,\n",
       " 'watch': 383,\n",
       " 'stuff': 384,\n",
       " 'ok': 385,\n",
       " 'move': 386,\n",
       " 'price': 387,\n",
       " \"we're\": 388,\n",
       " 'recommend': 389,\n",
       " 'shit': 390,\n",
       " 'question': 391,\n",
       " 'guy': 392,\n",
       " 'often': 393,\n",
       " 'power': 394,\n",
       " 'light': 395,\n",
       " 'team': 396,\n",
       " 'matter': 397,\n",
       " 'music': 398,\n",
       " 'remember': 399,\n",
       " 'comes': 400,\n",
       " 'line': 401,\n",
       " 'stay': 402,\n",
       " 'girl': 403,\n",
       " 'important': 404,\n",
       " 'code': 405,\n",
       " \"what's\": 406,\n",
       " 'men': 407,\n",
       " 'close': 408,\n",
       " 'given': 409,\n",
       " 'area': 410,\n",
       " 'test': 411,\n",
       " 'finally': 412,\n",
       " 'taking': 413,\n",
       " 'sometimes': 414,\n",
       " 'perfect': 415,\n",
       " 'ready': 416,\n",
       " 'quality': 417,\n",
       " 'seem': 418,\n",
       " 'awesome': 419,\n",
       " 'means': 420,\n",
       " 'needed': 421,\n",
       " 'black': 422,\n",
       " 'worth': 423,\n",
       " 'couple': 424,\n",
       " 'company': 425,\n",
       " 'heart': 426,\n",
       " 'hate': 427,\n",
       " 'cannot': 428,\n",
       " 'country': 429,\n",
       " 'past': 430,\n",
       " 'within': 431,\n",
       " 'running': 432,\n",
       " 'government': 433,\n",
       " \"wouldn't\": 434,\n",
       " 'okay': 435,\n",
       " 'tomorrow': 436,\n",
       " 'beautiful': 437,\n",
       " 'lost': 438,\n",
       " 'large': 439,\n",
       " 'front': 440,\n",
       " 'class': 441,\n",
       " 'young': 442,\n",
       " 'product': 443,\n",
       " 'file': 444,\n",
       " 'city': 445,\n",
       " 'asked': 446,\n",
       " 'upon': 447,\n",
       " 'outside': 448,\n",
       " 'group': 449,\n",
       " 'cause': 450,\n",
       " 'hear': 451,\n",
       " 'issues': 452,\n",
       " \"haven't\": 453,\n",
       " 'party': 454,\n",
       " 'deal': 455,\n",
       " 'heard': 456,\n",
       " 'white': 457,\n",
       " 'gets': 458,\n",
       " 'whether': 459,\n",
       " 'problems': 460,\n",
       " 'looked': 461,\n",
       " 'along': 462,\n",
       " 'site': 463,\n",
       " 'im': 464,\n",
       " 'half': 465,\n",
       " \"you'll\": 466,\n",
       " 'become': 467,\n",
       " 'tonight': 468,\n",
       " 'rest': 469,\n",
       " 'thinking': 470,\n",
       " 'pay': 471,\n",
       " 'inside': 472,\n",
       " 'turn': 473,\n",
       " 'kids': 474,\n",
       " 'clean': 475,\n",
       " 'yourself': 476,\n",
       " 'says': 477,\n",
       " 'above': 478,\n",
       " 'knew': 479,\n",
       " 'available': 480,\n",
       " 'future': 481,\n",
       " 'body': 482,\n",
       " \"couldn't\": 483,\n",
       " 'miss': 484,\n",
       " 'behind': 485,\n",
       " 'saying': 486,\n",
       " 'gave': 487,\n",
       " 'talking': 488,\n",
       " \"let's\": 489,\n",
       " 'reading': 490,\n",
       " 'public': 491,\n",
       " 'hot': 492,\n",
       " 'ago': 493,\n",
       " 'mr.': 494,\n",
       " 'message': 495,\n",
       " 'especially': 496,\n",
       " 'bring': 497,\n",
       " 'sense': 498,\n",
       " 'children': 499,\n",
       " 'early': 500,\n",
       " 'clear': 501,\n",
       " 'eyes': 502,\n",
       " 'felt': 503,\n",
       " 'women': 504,\n",
       " 'hey': 505,\n",
       " 'short': 506,\n",
       " 'taken': 507,\n",
       " 'process': 508,\n",
       " 'version': 509,\n",
       " 'eat': 510,\n",
       " \"she's\": 511,\n",
       " 'based': 512,\n",
       " 'goes': 513,\n",
       " 'local': 514,\n",
       " 'agree': 515,\n",
       " 'wants': 516,\n",
       " 'staff': 517,\n",
       " 'simply': 518,\n",
       " 'learn': 519,\n",
       " 'movie': 520,\n",
       " 'himself': 521,\n",
       " 'hair': 522,\n",
       " 'exactly': 523,\n",
       " 'enjoy': 524,\n",
       " 'war': 525,\n",
       " 'loved': 526,\n",
       " 'gone': 527,\n",
       " 'baby': 528,\n",
       " 'online': 529,\n",
       " 'special': 530,\n",
       " 'single': 531,\n",
       " 'news': 532,\n",
       " 'cool': 533,\n",
       " 'although': 534,\n",
       " 'happen': 535,\n",
       " 'happened': 536,\n",
       " 'forward': 537,\n",
       " 'account': 538,\n",
       " 'hit': 539,\n",
       " 'fix': 540,\n",
       " 'store': 541,\n",
       " 'unless': 542,\n",
       " 'due': 543,\n",
       " 'moment': 544,\n",
       " 'added': 545,\n",
       " 'fuck': 546,\n",
       " 'simple': 547,\n",
       " 'glad': 548,\n",
       " 'history': 549,\n",
       " 'general': 550,\n",
       " 'changes': 551,\n",
       " 'ones': 552,\n",
       " 'four': 553,\n",
       " 'fast': 554,\n",
       " 'hold': 555,\n",
       " 'feeling': 556,\n",
       " 'worked': 557,\n",
       " 'control': 558,\n",
       " 'project': 559,\n",
       " 'longer': 560,\n",
       " 'video': 561,\n",
       " 'provide': 562,\n",
       " 'return': 563,\n",
       " 'create': 564,\n",
       " 'woman': 565,\n",
       " 'sleep': 566,\n",
       " 'sound': 567,\n",
       " 'words': 568,\n",
       " 'example': 569,\n",
       " 'build': 570,\n",
       " 'plan': 571,\n",
       " 'table': 572,\n",
       " 'playing': 573,\n",
       " 'answer': 574,\n",
       " 'bought': 575,\n",
       " 'view': 576,\n",
       " 'near': 577,\n",
       " 'states': 578,\n",
       " \"you've\": 579,\n",
       " 'usually': 580,\n",
       " 'cold': 581,\n",
       " 'police': 582,\n",
       " 'wife': 583,\n",
       " 'itself': 584,\n",
       " 'perhaps': 585,\n",
       " 'link': 586,\n",
       " 'type': 587,\n",
       " 'interesting': 588,\n",
       " 'level': 589,\n",
       " 'bed': 590,\n",
       " 'source': 591,\n",
       " 'office': 592,\n",
       " 'across': 593,\n",
       " 'weekend': 594,\n",
       " 'cut': 595,\n",
       " 'form': 596,\n",
       " 'waiting': 597,\n",
       " 'ordered': 598,\n",
       " 'decided': 599,\n",
       " 'hands': 600,\n",
       " 'books': 601,\n",
       " 'strong': 602,\n",
       " 'super': 603,\n",
       " 'current': 604,\n",
       " 'market': 605,\n",
       " 'favorite': 606,\n",
       " 'watching': 607,\n",
       " 'write': 608,\n",
       " 'completely': 609,\n",
       " 'lol': 610,\n",
       " 'send': 611,\n",
       " 'user': 612,\n",
       " 'chance': 613,\n",
       " 'including': 614,\n",
       " 'door': 615,\n",
       " 'american': 616,\n",
       " 'sent': 617,\n",
       " 'alone': 618,\n",
       " 'president': 619,\n",
       " 'anyway': 620,\n",
       " 'fucking': 621,\n",
       " 'main': 622,\n",
       " 'known': 623,\n",
       " 'wonderful': 624,\n",
       " 'etc': 625,\n",
       " 'games': 626,\n",
       " 'dont': 627,\n",
       " 'word': 628,\n",
       " 'death': 629,\n",
       " 'takes': 630,\n",
       " 'son': 631,\n",
       " 'size': 632,\n",
       " 'town': 633,\n",
       " 'huge': 634,\n",
       " 'questions': 635,\n",
       " 'server': 636,\n",
       " 'mother': 637,\n",
       " 'excellent': 638,\n",
       " 'mine': 639,\n",
       " 'friendly': 640,\n",
       " 'months': 641,\n",
       " 'law': 642,\n",
       " 'email': 643,\n",
       " 'value': 644,\n",
       " 'human': 645,\n",
       " 'father': 646,\n",
       " 'red': 647,\n",
       " 'turned': 648,\n",
       " 'follow': 649,\n",
       " 'further': 650,\n",
       " 'personal': 651,\n",
       " 'living': 652,\n",
       " 'certain': 653,\n",
       " \"aren't\": 654,\n",
       " 'late': 655,\n",
       " 'among': 656,\n",
       " 'absolutely': 657,\n",
       " 'meet': 658,\n",
       " 'walk': 659,\n",
       " 'website': 660,\n",
       " 'community': 661,\n",
       " 'air': 662,\n",
       " 'report': 663,\n",
       " 'likely': 664,\n",
       " 'original': 665,\n",
       " 'visit': 666,\n",
       " 'five': 667,\n",
       " 'hell': 668,\n",
       " 'poor': 669,\n",
       " 'below': 670,\n",
       " 'month': 671,\n",
       " 'quickly': 672,\n",
       " 'expect': 673,\n",
       " 'health': 674,\n",
       " 'fresh': 675,\n",
       " 'girls': 676,\n",
       " 'changed': 677,\n",
       " 'review': 678,\n",
       " 'app': 679,\n",
       " 'following': 680,\n",
       " 'share': 681,\n",
       " 'fire': 682,\n",
       " 'whatever': 683,\n",
       " 'lots': 684,\n",
       " 'knows': 685,\n",
       " 'picture': 686,\n",
       " 'similar': 687,\n",
       " 'brought': 688,\n",
       " 'child': 689,\n",
       " 'dead': 690,\n",
       " 'difficult': 691,\n",
       " 'hours': 692,\n",
       " 'seemed': 693,\n",
       " 'access': 694,\n",
       " 'drive': 695,\n",
       " 'themselves': 696,\n",
       " 'quick': 697,\n",
       " 'break': 698,\n",
       " 'sounds': 699,\n",
       " 'boy': 700,\n",
       " 'highly': 701,\n",
       " 'content': 702,\n",
       " 'series': 703,\n",
       " 'sweet': 704,\n",
       " 'written': 705,\n",
       " 'space': 706,\n",
       " 'bar': 707,\n",
       " 'win': 708,\n",
       " 'fit': 709,\n",
       " 'sex': 710,\n",
       " 'expected': 711,\n",
       " 'comment': 712,\n",
       " 'wanna': 713,\n",
       " 'seeing': 714,\n",
       " 'services': 715,\n",
       " 'entire': 716,\n",
       " 'easily': 717,\n",
       " 'update': 718,\n",
       " 'stand': 719,\n",
       " 'writing': 720,\n",
       " 'low': 721,\n",
       " 'hour': 722,\n",
       " 'mom': 723,\n",
       " 'save': 724,\n",
       " 'continue': 725,\n",
       " 'action': 726,\n",
       " 'created': 727,\n",
       " 'major': 728,\n",
       " 'road': 729,\n",
       " 'offer': 730,\n",
       " 'weeks': 731,\n",
       " 'result': 732,\n",
       " 'damn': 733,\n",
       " 'kill': 734,\n",
       " 'received': 735,\n",
       " 'search': 736,\n",
       " 'welcome': 737,\n",
       " 'dog': 738,\n",
       " 'season': 739,\n",
       " 'birthday': 740,\n",
       " 'results': 741,\n",
       " 'ass': 742,\n",
       " 'wikipedia': 743,\n",
       " 'release': 744,\n",
       " 'amount': 745,\n",
       " 'correct': 746,\n",
       " 'pick': 747,\n",
       " 'dinner': 748,\n",
       " 'policy': 749,\n",
       " 'situation': 750,\n",
       " 'card': 751,\n",
       " 'text': 752,\n",
       " 'rom': 753,\n",
       " 'common': 754,\n",
       " 'fall': 755,\n",
       " 'shows': 756,\n",
       " 'sort': 757,\n",
       " 'church': 758,\n",
       " 'otherwise': 759,\n",
       " 'interested': 760,\n",
       " 'giving': 761,\n",
       " 'screen': 762,\n",
       " 'wonder': 763,\n",
       " 'stupid': 764,\n",
       " 'kept': 765,\n",
       " 'crazy': 766,\n",
       " 'song': 767,\n",
       " 'places': 768,\n",
       " 'national': 769,\n",
       " \"we'll\": 770,\n",
       " 'thread': 771,\n",
       " 'allow': 772,\n",
       " 'restaurant': 773,\n",
       " 'unfortunately': 774,\n",
       " 'cover': 775,\n",
       " 'members': 776,\n",
       " 'opinion': 777,\n",
       " 'interest': 778,\n",
       " 'husband': 779,\n",
       " 'present': 780,\n",
       " 'attention': 781,\n",
       " 'sick': 782,\n",
       " 'difference': 783,\n",
       " 'location': 784,\n",
       " 'certainly': 785,\n",
       " 'chicken': 786,\n",
       " 'united': 787,\n",
       " 'building': 788,\n",
       " 'security': 789,\n",
       " 'files': 790,\n",
       " 'research': 791,\n",
       " 'complete': 792,\n",
       " 'currently': 793,\n",
       " 'funny': 794,\n",
       " 'field': 795,\n",
       " 'web': 796,\n",
       " 'figure': 797,\n",
       " 'box': 798,\n",
       " 'happens': 799,\n",
       " 'lives': 800,\n",
       " 'south': 801,\n",
       " 'error': 802,\n",
       " 'mr': 803,\n",
       " 'social': 804,\n",
       " 'towards': 805,\n",
       " 'include': 806,\n",
       " 'rights': 807,\n",
       " 'court': 808,\n",
       " 'yesterday': 809,\n",
       " 'date': 810,\n",
       " 'totally': 811,\n",
       " 'pass': 812,\n",
       " 'john': 813,\n",
       " 'listen': 814,\n",
       " 'dark': 815,\n",
       " 'pain': 816,\n",
       " 'parents': 817,\n",
       " 'tired': 818,\n",
       " 'design': 819,\n",
       " 'step': 820,\n",
       " 'street': 821,\n",
       " 'shot': 822,\n",
       " 'coffee': 823,\n",
       " 'fan': 824,\n",
       " 'fight': 825,\n",
       " 'missing': 826,\n",
       " 'third': 827,\n",
       " 'choice': 828,\n",
       " 'key': 829,\n",
       " 'seriously': 830,\n",
       " 'lord': 831,\n",
       " 'style': 832,\n",
       " 'anymore': 833,\n",
       " 'sad': 834,\n",
       " 'moving': 835,\n",
       " 'political': 836,\n",
       " 'extra': 837,\n",
       " 'drink': 838,\n",
       " 'contact': 839,\n",
       " 'specific': 840,\n",
       " 'delicious': 841,\n",
       " 'cases': 842,\n",
       " 'position': 843,\n",
       " 'college': 844,\n",
       " 'sign': 845,\n",
       " 'truth': 846,\n",
       " 'customer': 847,\n",
       " 'users': 848,\n",
       " 'played': 849,\n",
       " 'program': 850,\n",
       " 'character': 851,\n",
       " 'note': 852,\n",
       " 'prices': 853,\n",
       " 'met': 854,\n",
       " 'subject': 855,\n",
       " 'comments': 856,\n",
       " 'lead': 857,\n",
       " 'safe': 858,\n",
       " 'choose': 859,\n",
       " 'gives': 860,\n",
       " 'forget': 861,\n",
       " 'moved': 862,\n",
       " 'event': 863,\n",
       " 'request': 864,\n",
       " 'consider': 865,\n",
       " 'starting': 866,\n",
       " 'removed': 867,\n",
       " 'battery': 868,\n",
       " 'summer': 869,\n",
       " 'green': 870,\n",
       " 'explain': 871,\n",
       " 'force': 872,\n",
       " 'brother': 873,\n",
       " 'ways': 874,\n",
       " 'board': 875,\n",
       " 'tv': 876,\n",
       " 'film': 877,\n",
       " 'products': 878,\n",
       " 'pictures': 879,\n",
       " 'details': 880,\n",
       " 'sources': 881,\n",
       " 'section': 882,\n",
       " 'middle': 883,\n",
       " 'deep': 884,\n",
       " 'patch': 885,\n",
       " 'remove': 886,\n",
       " 'taste': 887,\n",
       " 'overall': 888,\n",
       " 'characters': 889,\n",
       " 'friday': 890,\n",
       " 'english': 891,\n",
       " 'act': 892,\n",
       " 'necessary': 893,\n",
       " 'wow': 894,\n",
       " 'particular': 895,\n",
       " 'supposed': 896,\n",
       " 'truly': 897,\n",
       " 'snow': 898,\n",
       " 'parts': 899,\n",
       " 'north': 900,\n",
       " 'speak': 901,\n",
       " 'piece': 902,\n",
       " 'trust': 903,\n",
       " 'address': 904,\n",
       " 'cost': 905,\n",
       " 'except': 906,\n",
       " 'held': 907,\n",
       " 'menu': 908,\n",
       " 'enjoyed': 909,\n",
       " 'sit': 910,\n",
       " 'serious': 911,\n",
       " 'stock': 912,\n",
       " 'terms': 913,\n",
       " 'daughter': 914,\n",
       " 'n': 915,\n",
       " 'spend': 916,\n",
       " 'ideas': 917,\n",
       " 'lunch': 918,\n",
       " 'shall': 919,\n",
       " 'color': 920,\n",
       " 'internet': 921,\n",
       " 'join': 922,\n",
       " 'media': 923,\n",
       " 'computer': 924,\n",
       " 'dad': 925,\n",
       " 'became': 926,\n",
       " 'excited': 927,\n",
       " 'application': 928,\n",
       " 'therefore': 929,\n",
       " 'recently': 930,\n",
       " 'articles': 931,\n",
       " 'art': 932,\n",
       " 'evidence': 933,\n",
       " 'energy': 934,\n",
       " 'busy': 935,\n",
       " 'performance': 936,\n",
       " 'option': 937,\n",
       " 'various': 938,\n",
       " 'required': 939,\n",
       " 'ground': 940,\n",
       " 'immediately': 941,\n",
       " 'gotta': 942,\n",
       " 'easier': 943,\n",
       " 'cheap': 944,\n",
       " 'lose': 945,\n",
       " 'hurt': 946,\n",
       " 'fixed': 947,\n",
       " \"we've\": 948,\n",
       " 'development': 949,\n",
       " 'pull': 950,\n",
       " 'die': 951,\n",
       " 'thus': 952,\n",
       " 'oil': 953,\n",
       " 'normal': 954,\n",
       " 'paper': 955,\n",
       " 'member': 956,\n",
       " 'hi': 957,\n",
       " 'worse': 958,\n",
       " 'method': 959,\n",
       " 'clearly': 960,\n",
       " 'trip': 961,\n",
       " 'spot': 962,\n",
       " 'six': 963,\n",
       " 'weather': 964,\n",
       " 'worst': 965,\n",
       " 'throughout': 966,\n",
       " 'extremely': 967,\n",
       " 'pages': 968,\n",
       " 'asking': 969,\n",
       " 'ice': 970,\n",
       " 'discussion': 971,\n",
       " 'multiple': 972,\n",
       " 'paid': 973,\n",
       " 'none': 974,\n",
       " 'feels': 975,\n",
       " 'final': 976,\n",
       " 'spent': 977,\n",
       " 'lower': 978,\n",
       " 'attack': 979,\n",
       " 'killed': 980,\n",
       " 'liked': 981,\n",
       " 'involved': 982,\n",
       " 'blue': 983,\n",
       " 'nor': 984,\n",
       " 'voice': 985,\n",
       " 'sir': 986,\n",
       " 'earlier': 987,\n",
       " 'receive': 988,\n",
       " 'doubt': 989,\n",
       " 'items': 990,\n",
       " 'fair': 991,\n",
       " 'according': 992,\n",
       " 'slow': 993,\n",
       " 'noticed': 994,\n",
       " 'beyond': 995,\n",
       " 'luck': 996,\n",
       " 'vote': 997,\n",
       " 'decision': 998,\n",
       " 'shop': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_imagineville_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_words = [\"<s>\", \"</s>\", \".period\", \",comma\", \"!exclamation-point\", \"?question-mark\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping word: <s>\n",
      "Skipping word: </s>\n",
      "Skipping word: .period\n",
      "Skipping word: ,comma\n",
      "Skipping word: !exclamation-point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home3/ebrahim2/brainaudio/.venv/lib/python3.12/site-packages/g2p_en/g2p.py:156: SyntaxWarning: invalid escape sequence '\\-'\n",
      "  text = re.sub(\"[^ a-z'.,?!\\-]\", \"\", text)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping word: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m phonemes = \u001b[43mg2p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_txt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m phonemes = [re.sub(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[0-9]\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m phonemes]\n\u001b[32m     26\u001b[39m phonemes = [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m phonemes \u001b[38;5;28;01mif\u001b[39;00m re.match(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m^[A-Z]+$\u001b[39m\u001b[33m'\u001b[39m, p)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brainaudio/.venv/lib/python3.12/site-packages/g2p_en/g2p.py:179\u001b[39m, in \u001b[36mG2p.__call__\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    177\u001b[39m     pron = \u001b[38;5;28mself\u001b[39m.cmu[word][\u001b[32m0\u001b[39m]\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# predict for oov\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     pron = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m prons.extend(pron)\n\u001b[32m    182\u001b[39m prons.extend([\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brainaudio/.venv/lib/python3.12/site-packages/g2p_en/g2p.py:129\u001b[39m, in \u001b[36mG2p.predict\u001b[39m\u001b[34m(self, word)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, word):\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# encoder\u001b[39;00m\n\u001b[32m    128\u001b[39m     enc = \u001b[38;5;28mself\u001b[39m.encode(word)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     enc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc_w_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc_w_hh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m                   \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc_b_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc_b_hh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menc_w_hh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     last_hidden = enc[:, -\u001b[32m1\u001b[39m, :]\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# decoder\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brainaudio/.venv/lib/python3.12/site-packages/g2p_en/g2p.py:115\u001b[39m, in \u001b[36mG2p.gru\u001b[39m\u001b[34m(self, x, steps, w_ih, w_hh, b_ih, b_hh, h0)\u001b[39m\n\u001b[32m    113\u001b[39m outputs = np.zeros((x.shape[\u001b[32m0\u001b[39m], steps, w_hh.shape[\u001b[32m1\u001b[39m]), np.float32)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrucell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_hh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_ih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_hh\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (b, h)\u001b[39;00m\n\u001b[32m    116\u001b[39m     outputs[:, t, ::] = h\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brainaudio/.venv/lib/python3.12/site-packages/g2p_en/g2p.py:96\u001b[39m, in \u001b[36mG2p.grucell\u001b[39m\u001b[34m(self, x, h, w_ih, w_hh, b_ih, b_hh)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrucell\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h, w_ih, w_hh, b_ih, b_hh):\n\u001b[32m     95\u001b[39m     rzn_ih = np.matmul(x, w_ih.T) + b_ih\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     rzn_hh = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_hh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m + b_hh\n\u001b[32m     98\u001b[39m     rz_ih, n_ih = rzn_ih[:, :rzn_ih.shape[-\u001b[32m1\u001b[39m] * \u001b[32m2\u001b[39m // \u001b[32m3\u001b[39m], rzn_ih[:, rzn_ih.shape[-\u001b[32m1\u001b[39m] * \u001b[32m2\u001b[39m // \u001b[32m3\u001b[39m:]\n\u001b[32m     99\u001b[39m     rz_hh, n_hh = rzn_hh[:, :rzn_hh.shape[-\u001b[32m1\u001b[39m] * \u001b[32m2\u001b[39m // \u001b[32m3\u001b[39m], rzn_hh[:, rzn_hh.shape[-\u001b[32m1\u001b[39m] * \u001b[32m2\u001b[39m // \u001b[32m3\u001b[39m:]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "imagineville_vocab_file = \"/data2/brain2text/lm/vocab_lower_100k.txt\"\n",
    "g2p = G2p()\n",
    "\n",
    "with open (imagineville_vocab_file, mode=\"r\") as f:\n",
    "    \n",
    "    imagineville_vocab = f.readlines()\n",
    "    \n",
    "allowed_punctuation = \"!,.'?'\"\n",
    "allowed_chars = set(string.ascii_letters + allowed_punctuation)\n",
    "\n",
    "punctuation_chars = set(string.punctuation)\n",
    "\n",
    "lexicon_char_imagineville = []\n",
    "lexicon_phoneme_imagineville = []\n",
    "\n",
    "for word_txt in imagineville_vocab:\n",
    "    \n",
    "    word_txt = word_txt.strip()\n",
    "    \n",
    "    if word_txt in skip_words:\n",
    "        print(f\"Skipping word: {word_txt}\")\n",
    "        continue\n",
    "    \n",
    "    phonemes = g2p(word_txt)\n",
    "    phonemes = [re.sub(r'[0-9]', '', p) for p in phonemes]\n",
    "    phonemes = [p for p in phonemes if re.match(r'^[A-Z]+$', p)]\n",
    "    phonemes = \" \".join(phonemes)\n",
    "    \n",
    "    formatted_string_phoneme = f\"{word_txt} {phonemes} |\"\n",
    "    \n",
    "    lexicon_phoneme_imagineville.append(formatted_string_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagineville_vocab_file_pytorch_phoneme = \"/data2/brain2text/lm/vocab_lower_100k_pytorch_phoneme.txt\"\n",
    "\n",
    "with open(imagineville_vocab_file_pytorch_phoneme, mode=\"w\") as file:\n",
    "    \n",
    "    for item in lexicon_phoneme_imagineville:\n",
    "\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model_path = \"/data2/brain2text/lm/languageModel/\"\n",
    "units_txt_file = f\"{language_model_path}units.txt\"\n",
    "\n",
    "with open(units_txt_file, mode=\"r\") as f:\n",
    "\n",
    "    units_original = f.readlines()\n",
    "    \n",
    "units = [\"-\"]\n",
    "for line in units_original:\n",
    "    units.append(line.split(' ')[0])\n",
    "units.append(\"|\")\n",
    "\n",
    "units_txt_file_pytorch = f\"{language_model_path}units_pytorch.txt\"\n",
    "\n",
    "with open(units_txt_file_pytorch, mode=\"w\") as file:\n",
    "    \n",
    "    for item in units:\n",
    "        file.write(f\"{item}\\n\")\n",
    "    \n",
    "    \n",
    "lexicon_file = f\"{language_model_path}lexicon_numbers.txt\"\n",
    "\n",
    "with open(lexicon_file, mode=\"r\") as f:\n",
    "\n",
    "    lexicon_original = f.readlines()\n",
    "\n",
    "lexicon = []\n",
    "words_only = {}\n",
    "for word in lexicon_original:\n",
    "    \n",
    "    word_txt = word.split(\" \")[0]\n",
    "    words_only[word_txt.strip()] = 0\n",
    "    word_numbers = word.replace(\"\\n\", \"\").split(' ')[1:]\n",
    "    word_number_str = f\"{word_txt.lower()}\"\n",
    "    \n",
    "    for wn in word_numbers:\n",
    "        word_number_str += f\" {units[int(wn)]}\"\n",
    "        \n",
    "    word_number_str += \" |\"\n",
    "    lexicon.append(word_number_str)\n",
    "\n",
    "lexicon_phonemes_file = f\"{language_model_path}lexicon_phonemes.txt\"\n",
    "\n",
    "        \n",
    "with open(lexicon_phonemes_file, mode=\"w\") as file:\n",
    "    \n",
    "    for item in lexicon:\n",
    "\n",
    "        file.write(f\"{item}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sp>', '!', ',', '.', '?', \"'\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "-\n",
      "|\n",
      "!\n",
      ",\n",
      ".\n",
      "?\n",
      "'\n",
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "k\n",
      "l\n",
      "m\n",
      "n\n",
      "o\n",
      "p\n",
      "q\n",
      "r\n",
      "s\n",
      "t\n",
      "u\n",
      "v\n",
      "w\n",
      "x\n",
      "y\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "CHAR_VOCAB = [\n",
    "    \"<sp>\",          # space token\n",
    "    \"!\", \",\", \".\", \"?\", \"'\",   # punctuation (incl. apostrophe)\n",
    "] + [chr(i) for i in range(ord('a'), ord('z') + 1)]  # 'a'..'z'\n",
    "\n",
    "# Build mappings\n",
    "_CHAR_TO_ID = {c: i for i, c in enumerate(CHAR_VOCAB)}\n",
    "_ID_TO_CHAR = {i: c for c, i in _CHAR_TO_ID.items()}\n",
    "\n",
    "# Convenience indices\n",
    "SPACE_ID = _CHAR_TO_ID[\"<sp>\"]\n",
    "\n",
    "print(CHAR_VOCAB)\n",
    "\n",
    "\n",
    "character_units = [\"-\"]\n",
    "for cv in CHAR_VOCAB:\n",
    "    \n",
    "    if cv == \"<sp>\":\n",
    "        character_units.append(\"|\")\n",
    "    else:\n",
    "        character_units.append(cv)\n",
    "        \n",
    "units_txt_file_pytorch_char = f\"{language_model_path}units_pytorch_character.txt\"\n",
    "\n",
    "with open(units_txt_file_pytorch_char, mode=\"w\") as file:\n",
    "    \n",
    "    for item in character_units:\n",
    "        print(item)\n",
    "        file.write(f\"{item}\\n\")\n",
    "        \n",
    "import string\n",
    "lexicon_char = []\n",
    "allowed_punctuation = \"!,.'?'\"\n",
    "allowed_chars = set(string.ascii_letters + allowed_punctuation)\n",
    "for word in lexicon_original:\n",
    "    \n",
    "    word_txt = word.split(\" \")[0].lower()\n",
    "    \n",
    "    \"\"\"\n",
    "    convert word to character format\n",
    "    so if word is TREE, then create a str of the following format:\n",
    "    TREE t r e e | \n",
    "    \n",
    "    The vocabulary consists of characters as well as the following punctuation marks: '!', ',', '.', '?', \"'\", \n",
    "    Skip all words that contain numbers\n",
    "    \n",
    "    Once you have created the string, append it to the lexicon.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the word contains any numbers\n",
    "    if any(char.isdigit() for char in word_txt):\n",
    "        continue  # Skip this word if it has numbers\n",
    "    \n",
    "    if any(char not in allowed_chars for char in word_txt):\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Get the lowercase version of the word\n",
    "    lower_chars = word_txt.lower()\n",
    "    \n",
    "    # Create the spaced-out character string\n",
    "    spaced_chars = \" \".join(lower_chars)\n",
    "    \n",
    "    # Format the final string as required\n",
    "    formatted_string = f\"{word_txt} {spaced_chars} |\"\n",
    "    \n",
    "    # Append the formatted string to the lexicon\n",
    "    lexicon_char.append(formatted_string)\n",
    "    \n",
    "    \n",
    "lexicon_char_file= f\"{language_model_path}lexicon_char.txt\"\n",
    "\n",
    "with open(lexicon_char_file, mode=\"w\") as file:\n",
    "    \n",
    "    for item in lexicon_char:\n",
    "\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '|',\n",
       " '!',\n",
       " ',',\n",
       " '.',\n",
       " '?',\n",
       " \"'\",\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n"
     ]
    }
   ],
   "source": [
    "print(units[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alvita a l v i t a |'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_char[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAKER AA K ER |'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
