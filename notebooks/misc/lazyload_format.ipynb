{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51ef36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f6f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2t_24 = pd.read_pickle(\"/data2/brain2text/b2t_24/brain2text24.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2831bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Processing participant 0 from /data2/brain2text/b2t_24/brain2text24.pkl...\n",
      "Processing participant 1 from /data2/brain2text/b2t_25/brain2text25.pkl...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Handle test mode (missing keys)\u001b[39;00m\n\u001b[32m     44\u001b[39m is_test = \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m split_data[day]\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m transcript = (\u001b[43msplit_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mday\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtranscriptions\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m]\u001b[49m \n\u001b[32m     47\u001b[39m               \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_test \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mFILLER\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m text = (split_data[day][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m][trial] \n\u001b[32m     50\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_test \u001b[38;5;28;01melse\u001b[39;00m np.array([\u001b[32m0\u001b[39m], dtype=np.int32))\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Save all trial data to a single compressed .npz file\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# We also save 'pid', 'day', and 'trial' as metadata\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "data_paths = ['/data2/brain2text/b2t_24/brain2text24.pkl', '/data2/brain2text/b2t_25/brain2text25.pkl']\n",
    "output_dirs = ['/data2/brain2text/b2t_24/trial_level_data/', '/data2/brain2text/b2t_25/trial_level_data/']\n",
    "# ---------------------\n",
    "\n",
    "print(\"Starting preprocessing...\")\n",
    "file_manifest = {'train': [], 'val': [], 'test': []} # To save paths\n",
    "\n",
    "for p_id, pkl_path in enumerate(data_paths):\n",
    "    print(f\"Processing participant {p_id} from {pkl_path}...\")\n",
    "    \n",
    "    output_dir = output_dirs[p_id]\n",
    "    \n",
    "    with open(pkl_path, \"rb\") as handle:\n",
    "        participant_data = pickle.load(handle)\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if split not in participant_data:\n",
    "            continue\n",
    "            \n",
    "        split_data = participant_data[split]\n",
    "        \n",
    "        for day in range(len(split_data)):\n",
    "            if split_data[day] is None:\n",
    "                continue\n",
    "            \n",
    "            # Use 'sentenceDat' to find the number of trials\n",
    "            n_trials = len(split_data[day][\"sentenceDat\"])\n",
    "            \n",
    "            for trial in range(n_trials):\n",
    "                # Define where to save this single trial\n",
    "                trial_dir = f\"{output_dir}/{split}\"\n",
    "                os.makedirs(trial_dir, exist_ok=True)\n",
    "                trial_path = f\"{trial_dir}/day_{day}_trial_{trial}.npz\"\n",
    "                \n",
    "                # --- Get the data for this trial ---\n",
    "                sentenceDat = split_data[day][\"sentenceDat\"][trial]\n",
    "                \n",
    "                # Handle test mode (missing keys)\n",
    "                is_test = \"text\" not in split_data[day]\n",
    "                \n",
    "                transcript = (split_data[day]['transcriptions'][trial] \n",
    "                              if not is_test else \"FILLER\")\n",
    "                \n",
    "                text = (split_data[day][\"text\"][trial] \n",
    "                        if not is_test else np.array([0], dtype=np.int32))\n",
    "\n",
    "                # Save all trial data to a single compressed .npz file\n",
    "                # We also save 'pid', 'day', and 'trial' as metadata\n",
    "                np.savez_compressed(\n",
    "                    trial_path,\n",
    "                    sentenceDat=sentenceDat,\n",
    "                    transcription=np.array(transcript, dtype=object), # Save string as 0-D object array\n",
    "                    text=text,\n",
    "                    pid=p_id,\n",
    "                    day=day\n",
    "                )\n",
    "                \n",
    "                # Add the new file path to our manifest\n",
    "                file_manifest[split].append(str(trial_path))\n",
    "\n",
    "print(\"Done preprocessing.\")\n",
    "\n",
    "# Optionally, save the manifest of all file paths for easy loading\n",
    "with open(output_dir / \"manifest.json\", \"w\") as f:\n",
    "    import json\n",
    "    json.dump(file_manifest, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "443c06e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 28, 40, 35, 11, 28, 18, 40,  3, 14, 11, 20, 30,  3, 23,  3,\n",
       "       31, 40, 36, 17, 10, 40, 36,  3, 23, 40,  3, 23,  3, 10, 12, 40,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39e5687c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They're very affectionate with one another.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffcb1f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(split_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d48e8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(split_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bafe5a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('preprocessed_dataset_npz/participant_1/test/day_1_trial_0.npz')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "024324c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(split_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8de10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
