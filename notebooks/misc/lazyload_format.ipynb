{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ef36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1f6f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2t_24 = pd.read_pickle(\"/data2/brain2text/b2t_24/brain2text24.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83383ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "total_trials = 0\n",
    "split = \"test\"\n",
    "for i in range(len(b2t_24[split])):\n",
    "    if b2t_24[split][i] is None:\n",
    "        continue\n",
    "    num_train_trials = len(b2t_24[split][i][\"sentenceDat\"])\n",
    "    total_trials += num_train_trials\n",
    "    \n",
    "print(total_trials)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831bc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Processing participant 0 from /data2/brain2text/b2t_25/brain2text25.pkl...\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "data_paths = ['/data2/brain2text/b2t_25/brain2text25.pkl', '/data2/brain2text/b2t_24/brain2text24.pkl']\n",
    "output_dirs = ['/data2/brain2text/b2t_25/trial_level_data/', '/data2/brain2text/b2t_24/trial_level_data/']\n",
    "# ---------------------\n",
    "\n",
    "print(\"Starting preprocessing...\")\n",
    "file_manifest = {'train': [], 'val': [], 'test': []} # To save paths\n",
    "\n",
    "for p_id, pkl_path in enumerate(data_paths):\n",
    "    print(f\"Processing participant {p_id} from {pkl_path}...\")\n",
    "    \n",
    "    output_dir = output_dirs[p_id]\n",
    "    \n",
    "    with open(pkl_path, \"rb\") as handle:\n",
    "        participant_data = pickle.load(handle)\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if split not in participant_data:\n",
    "            continue\n",
    "            \n",
    "        split_data = participant_data[split]\n",
    "        \n",
    "        if split == \"test\":\n",
    "            is_test = True\n",
    "        else:\n",
    "            is_test = False\n",
    "        \n",
    "        for day in range(len(split_data)):\n",
    "            \n",
    "            if split_data[day] is None:\n",
    "                continue\n",
    "            \n",
    "            # Use 'sentenceDat' to find the number of trials\n",
    "            n_trials = len(split_data[day][\"sentenceDat\"])\n",
    "            \n",
    "            for trial in range(n_trials):\n",
    "                # Define where to save this single trial\n",
    "                trial_dir = f\"{output_dir}/{split}\"\n",
    "                os.makedirs(trial_dir, exist_ok=True)\n",
    "                trial_path = f\"{trial_dir}/day_{day}_trial_{trial}.npz\"\n",
    "                \n",
    "                # --- Get the data for this trial ---\n",
    "                sentenceDat = split_data[day][\"sentenceDat\"][trial]\n",
    "                                \n",
    "                transcript = (split_data[day]['transcriptions'][trial] \n",
    "                              if not is_test else \"FILLER\")\n",
    "                \n",
    "                text = (split_data[day][\"text\"][trial] \n",
    "                        if not is_test else np.array([0], dtype=np.int32))\n",
    "\n",
    "                # Save all trial data to a single compressed .npz file\n",
    "                # We also save 'pid', 'day', and 'trial' as metadata\n",
    "                np.savez_compressed(\n",
    "                    trial_path,\n",
    "                    sentenceDat=sentenceDat,\n",
    "                    transcription=np.array(transcript, dtype=object), # Save string as 0-D object array\n",
    "                    text=text,\n",
    "                    pid=p_id,\n",
    "                    day=day\n",
    "                )\n",
    "                \n",
    "                # Add the new file path to our manifest\n",
    "                file_manifest[split].append(str(trial_path))\n",
    "\n",
    "print(\"Done preprocessing.\")\n",
    "\n",
    "# Optionally, save the manifest of all file paths for easy loading\n",
    "with open(output_dir / \"manifest.json\", \"w\") as f:\n",
    "    import json\n",
    "    json.dump(file_manifest, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0580941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
