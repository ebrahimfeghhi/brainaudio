{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ours_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m baseline_ref = \u001b[32m9.76\u001b[39m \u001b[38;5;66;03m# from eval AI \u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Perform One-Sample T-Test\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# This checks if the mean of 'ours_data' is significantly different from 9.76\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m t_stat, p_value = stats.ttest_1samp(\u001b[43mours_data\u001b[49m, baseline_ref)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Calculate descriptive statistics for context\u001b[39;00m\n\u001b[32m     10\u001b[39m mean_ours = np.mean(ours_data)\n",
      "\u001b[31mNameError\u001b[39m: name 'ours_data' is not defined"
     ]
    }
   ],
   "source": [
    "main_results = np.load(\"saved_data/main_results.npy\")\n",
    "baseline_ref = 9.76 # from eval AI \n",
    "\n",
    "\n",
    "# Perform One-Sample T-Test\n",
    "# This checks if the mean of 'ours_data' is significantly different from 9.76\n",
    "t_stat, p_value = stats.ttest_1samp(main_results, baseline_ref)\n",
    "\n",
    "# Calculate descriptive statistics for context\n",
    "mean_ours = np.mean(main_results)\n",
    "std_ours = np.std(main_results, ddof=1) # Sample standard deviation\n",
    "\n",
    "print(f\"--- Results ---\")\n",
    "print(f\"Mean of 'Ours': {mean_ours:.4f} (vs Baseline: {baseline_ref})\")\n",
    "print(f\"T-statistic:    {t_stat:.5f}\")\n",
    "print(f\"P-value:        {p_value:.5f}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nConclusion: The difference is statistically significant (Reject H0).\")\n",
    "    if mean_ours > baseline_ref:\n",
    "        print(\"Your model is significantly worse than baseline.\")\n",
    "    else:\n",
    "        print(\"Your model is significantly better than baseline.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: The difference is NOT statistically significant (Fail to reject H0).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LEFT Values Results (vs 6.999) ---\n",
      "Mean: 6.4665\n",
      "T-statistic: -11.70484\n",
      "P-value: 0.00000\n",
      "Result: Statistically significant difference.\n",
      "\n",
      "--- RIGHT Values Results (vs 6.67) ---\n",
      "Mean: 5.7691\n",
      "T-statistic: -7.92002\n",
      "P-value: 0.00002\n",
      "Result: Statistically significant difference.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "#\n",
    "\n",
    "# Private Score\n",
    "left_values = [\n",
    "    6.465,   # Seed 1\n",
    "    6.497,   # Seed 2\n",
    "    6.591,   # Seed 3\n",
    "    6.183,   # Seed 4\n",
    "    6.340,   # Seed 5\n",
    "    6.324,   # Seed 6\n",
    "    6.528,   # Seed 7\n",
    "    6.544,   # Seed 8\n",
    "    6.6654,  # Seed 9\n",
    "    6.528    # Seed 10\n",
    "]\n",
    "\n",
    "# List 2: Values on the RIGHT of the comma\n",
    "right_values = [\n",
    "    5.909,   # Seed 1\n",
    "    5.787,   # Seed 2\n",
    "    5.848,   # Seed 3\n",
    "    5.424,   # Seed 4\n",
    "    5.393,   # Seed 5\n",
    "    6.363,   # Seed 6\n",
    "    5.242,   # Seed 7 \n",
    "    6.181,   # Seed 8\n",
    "    5.575,   # Seed 9\n",
    "    5.969    # Seed 10\n",
    "]\n",
    "\n",
    "# Reference values from \"5-gram + OPT\" Seed 10\n",
    "ref_left = 6.999\n",
    "ref_right = 6.67\n",
    "\n",
    "# Perform One-Sample T-Test for the LEFT values\n",
    "t_stat_left, p_val_left = stats.ttest_1samp(left_values, ref_left)\n",
    "\n",
    "# Perform One-Sample T-Test for the RIGHT values\n",
    "t_stat_right, p_val_right = stats.ttest_1samp(right_values, ref_right)\n",
    "\n",
    "# Output Results\n",
    "print(\"--- LEFT Values Results (vs 6.999) ---\")\n",
    "print(f\"Mean: {sum(left_values)/len(left_values):.4f}\")\n",
    "print(f\"T-statistic: {t_stat_left:.5f}\")\n",
    "print(f\"P-value: {p_val_left:.5f}\")\n",
    "if p_val_left < 0.05:\n",
    "    print(\"Result: Statistically significant difference.\")\n",
    "else:\n",
    "    print(\"Result: No statistically significant difference.\")\n",
    "\n",
    "print(\"\\n--- RIGHT Values Results (vs 6.67) ---\")\n",
    "print(f\"Mean: {sum(right_values)/len(right_values):.4f}\")\n",
    "print(f\"T-statistic: {t_stat_right:.5f}\")\n",
    "print(f\"P-value: {p_val_right:.5f}\")\n",
    "if p_val_right < 0.05:\n",
    "    print(\"Result: Statistically significant difference.\")\n",
    "else:\n",
    "    print(\"Result: No statistically significant difference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
