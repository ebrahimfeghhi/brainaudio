{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import scipy.stats as stats\n",
            "import numpy as np\n",
            "import sys\n",
            "sys.path.append('..')\n",
            "from utils import get_wer_values\n",
            "import pandas as pd"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Data from eval AI for test set"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "llama_1b_4_gram = [\n",
            "    9.23,   # Seed 1\n",
            "    9.04,   # Seed 2\n",
            "    9.095,  # Seed 3\n",
            "    9.825,  # Seed 4\n",
            "    9.338,  # Seed 5\n",
            "    9.446,  # Seed 6\n",
            "    9.257,  # Seed 7\n",
            "    9.379,  # Seed 8\n",
            "    9.717,  # Seed 9\n",
            "    9.405   # Seed 10\n",
            "]\n",
            "\n",
            "# The single Baseline value to test against\n",
            "baseline_ref = 9.76\n",
            "\n",
            "np.save(\"saved_data/main_results\", llama_1b_4_gram)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Val Set Baseline"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Val WER\n",
            "val_score = [\n",
            "    14.10,  # seed0\n",
            "    13.90,  # seed1\n",
            "    14.41,  # seed2\n",
            "    14.61,  # seed3\n",
            "    13.90,  # seed4\n",
            "    14.14,  # seed5\n",
            "    14.28,  # seed6\n",
            "    14.19,  # seed7\n",
            "    13.90,  # seed8\n",
            "    14.26   # seed9\n",
            "]\n",
            "\n",
            "\n",
            "np.save(\"saved_data/val_scores\", val_score)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Ablation #1: Calling LLM Only Once at the End of Decoding\n",
            "Only appply LLM rescoring once trial has finished."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "10\n"
               ]
            }
         ],
         "source": [
            "wer, csv_files = get_wer_values(\"../../results/b2t_24\", \"no_delayed_fusion\")\n",
            "print(len(wer))\n",
            "np.save(\"saved_data/no_delayed_fusion_ablation\", wer)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Ablation #2: Using Non-Finetuned LLM\n",
            "Use LLM that has not been fine-tuned to do next-word prediction on training set."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "10\n"
               ]
            }
         ],
         "source": [
            "wer, csv_files = get_wer_values(\"../../results/b2t_24\", \"no_finetuning\")\n",
            "print(len(wer))\n",
            "np.save(\"saved_data/no_finetuning_ablation\", wer)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Ablation #3: Remove multiple phoneme variants\n",
            "Each word only has a single phoneme sequence."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "10\n"
               ]
            }
         ],
         "source": [
            "wer, csv_files = get_wer_values(\"../../results/b2t_24\", \"no_variants\")\n",
            "print(len(wer))\n",
            "np.save(\"saved_data/no_variants_ablation\", wer)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Ablation #4: llama-3B finetuned\n",
            "Use the finetuned 3B model for delayed fusion."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "10\n"
               ]
            }
         ],
         "source": [
            "wer, csv_files = get_wer_values(\"../../results/b2t_24\", \"llama_3b\")\n",
            "print(len(wer))\n",
            "np.save(\"saved_data/llama_3b_ablation\", wer)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "ename": "FileNotFoundError",
               "evalue": "[Errno 2] No such file or directory: '../../results/transformer'",
               "output_type": "error",
               "traceback": [
                  "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                  "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                  "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m wer, csv_files = \u001b[43mget_wer_values\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../../results/transformer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllama_1b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(wer))\n\u001b[32m      3\u001b[39m np.save(\u001b[33m\"\u001b[39m\u001b[33msaved_data/b2t24_combined_transformer\u001b[39m\u001b[33m\"\u001b[39m, wer)\n",
                  "\u001b[36mFile \u001b[39m\u001b[32m~/brainaudio/figure_data/b2t_24_results/../utils.py:12\u001b[39m, in \u001b[36mget_wer_values\u001b[39m\u001b[34m(results_folder, str_identifier)\u001b[39m\n\u001b[32m     10\u001b[39m wer_values = []\n\u001b[32m     11\u001b[39m file_names = []\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fname.endswith(\u001b[33m'\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m str_identifier \u001b[38;5;129;01min\u001b[39;00m fname:\n\u001b[32m     14\u001b[39m         fpath = os.path.join(results_folder, fname)\n",
                  "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../../results/transformer'"
               ]
            }
         ],
         "source": [
            "wer, csv_files = get_wer_values(\"../../results/transformer\", \"llama_1b\")\n",
            "print(len(wer))\n",
            "np.save(\"saved_data/b2t24_combined_transformer\", wer)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[0.13336972343522563,\n",
                     " 0.14610625909752548,\n",
                     " 0.1319141193595342,\n",
                     " 0.12063318777292577,\n",
                     " 0.13155021834061134,\n",
                     " 0.1304585152838428,\n",
                     " 0.12554585152838427,\n",
                     " 0.13664483260553129,\n",
                     " 0.12463609898107715,\n",
                     " 0.12954876273653565]"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "wer\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "brainaudio",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.3"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}