{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02167edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pickle\n",
    "import numpy as np\n",
    "from llm_utils import cer_with_gpt2_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f62025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf78c99a27db44faab41abcb584b5f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of AI is in the hands of the people\n",
      "\n",
      "The future of AI is in the hands of the people\n",
      "\n",
      "The future of AI is in the hands of the people\n",
      "\n",
      "The future of AI is in the hands of the people\n",
      "\n",
      "The future of\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/opt-6.7b\"\n",
    "\n",
    "# Load tokenizer\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model in 8-bit with automatic device placement\n",
    "llm = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Example: Generate from a prompt\n",
    "inputs = llm_tokenizer(\"The future of AI is\", return_tensors=\"pt\").to(llm.device)\n",
    "outputs = llm.generate(**inputs, max_new_tokens=50)\n",
    "print(llm_tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12455693",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic_scale = 0.5\n",
    "llm_weight = 0.5\n",
    "seed_list = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248590b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ebrahim/data2/brain2text/b2t_24/model_outputs/bidirectional_gru_test/bidirectional_gru_seed_0_nbest_5gram.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_outputs_path, mode = \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     model_outputs = pickle.load(f)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnbest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      8\u001b[39m     nbest = pickle.load(f)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_outputs[\u001b[33m'\u001b[39m\u001b[33mtranscriptions\u001b[39m\u001b[33m'\u001b[39m])):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/brainaudio/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    342\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/ebrahim/data2/brain2text/b2t_24/model_outputs/bidirectional_gru_test/bidirectional_gru_seed_0_nbest_5gram.pkl'"
     ]
    }
   ],
   "source": [
    "nbest_path = \"/home/ebrahim/data2/brain2text/b2t_24/model_outputs/bidirectional_gru_test/bidirectional_gru_seed_0_nbest_5gram.pk\"\n",
    "model_outputs_path = \"/home/ebrahim/data2/brain2text/b2t_24/model_outputs/bidirectional_gru_test/bidirectional_gru_seed_0_model_outputs.pkl\"\n",
    "\n",
    "with open(model_outputs_path, mode = 'rb') as f:\n",
    "    model_outputs = pickle.load(f)\n",
    "    \n",
    "with open(nbest_path, mode = 'rb') as f:\n",
    "    nbest = pickle.load(f)\n",
    "\n",
    "for i in range(len(model_outputs['transcriptions'])):\n",
    "    new_trans = [ord(c) for c in model_outputs['transcriptions'][i]] + [0]\n",
    "    model_outputs['transcriptions'][i] = np.array(new_trans)\n",
    "    \n",
    "\n",
    "# Rescore nbest outputs with LLM\n",
    "llm_out = cer_with_gpt2_decoder(\n",
    "    llm,\n",
    "    llm_tokenizer,\n",
    "    nbest[:],\n",
    "    acoustic_scale,\n",
    "    model_outputs,\n",
    "    outputType=\"speech_sil\",\n",
    "    returnCI=True,\n",
    "    lengthPenalty=0,\n",
    "    alpha=llm_weight,\n",
    ")\n",
    "\n",
    "\n",
    "with open(\"/home/ebrahim/data2/brain2text/b2t_24/model_outputs/bidirectional_gru_test/bidirectional_gru_seed_0_llm_outs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(llm_out['decoded_transcripts'])+ \"\\n\")   # one line per LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9514ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b6130b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.15439170758319695),\n",
       " np.float64(0.14027706574962823),\n",
       " np.float64(0.16899384824954927))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_out[\"wer\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf87f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
