{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a hacky import since brainaudio requires python 3.12 and the .wfst env requires an older\n",
    "# python version \n",
    "import importlib                                                                                                                                                                                                    \n",
    "import wfst_utils\n",
    "importlib.reload(wfst_utils)\n",
    "from wfst_utils import build_lm_decoder, lm_decode, arrange_logits, _cer_and_wer, augment_nbest\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys                                                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'b2t_25'\n",
    "load_lm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"b2t_25\":\n",
    "    blank_penalty = np.log(90)\n",
    "    acoustic_scale = 0.325\n",
    "    beam = 17\n",
    "    rescore = True\n",
    "    base_path = \"/home/ebrahim/data2/brain2text/b2t_25/logits/\"\n",
    "    save_path = \"/home/ebrahim/data2/brain2text/b2t_25/wfst_outputs/\"\n",
    "\n",
    "    \n",
    "if dataset == \"b2t_24\":\n",
    "    blank_penalty = np.log(7)\n",
    "    acoustic_scale = 0.5\n",
    "    beam = 18\n",
    "    rescore = True\n",
    "    base_path = \"/home/ebrahim/data2/brain2text/b2t_24/logits/\"\n",
    "    save_path = \"/home/ebrahim/data2/brain2text/b2t_24/wfst_outputs/\"\n",
    "    \n",
    "lmDir = \"/home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test\"\n",
    "nbest_value = 100\n",
    "return_n_best = True\n",
    "ms_per_output = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded LM\n",
      "Peak RSS after LM load: 300.19 GB (delta: 299.99 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0219 21:10:37.238173 2062165 brain_speech_decoder.h:52] Reading fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/TLG.fst\n",
      "I0219 21:12:42.693130 2062165 brain_speech_decoder.h:58] Reading lm fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/G.fst\n",
      "I0219 21:13:09.267980 2062165 brain_speech_decoder.h:70] Reading rescore fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/G_no_prune.fst\n",
      "I0219 21:21:58.539877 2062165 brain_speech_decoder.h:81] Reading symbol table /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/words.txt\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "\n",
    "rss_before = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "if load_lm and 'ngramDecoder' not in globals(): \n",
    "    \n",
    "    ngramDecoder = build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=nbest_value,\n",
    "        beam=beam,\n",
    "    )\n",
    "    print(\"loaded LM\")\n",
    "\n",
    "rss_after = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "print(f\"Peak RSS after LM load: {rss_after / (1024**2):.2f} GB (delta: {(rss_after - rss_before) / (1024**2):.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name\n",
    "seeds_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "folder_name = [f\"neurips_b2t_25_causal_transformer_v4_prob_1_seed_{i}\" for i in seeds_list]\n",
    "logits_file_name = [\"logits_test_chunk:1_context:20.npz\"] * len(seeds_list)\n",
    "nbest_save_path_arr = [f\"time_masked_transformer_25/seed_{i}_test\" for i in seeds_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ebrahim/data2/brain2text/b2t_25/logits/baseline_rnn_ucd_seeds_1_to_9/neurips_b2t_25_causal_transformer_v4_prob_1_seed_0/logits_test_chunk:1_context:20.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m rescore_bool \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m fn, lm, nb \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(folder_name, logits_file_name, nbest_save_path_arr):\n\u001b[0;32m---> 12\u001b[0m     logits_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mbase_path\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mfn\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mlm\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m     nbest_save_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msave_path\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mnb\u001b[39m}\u001b[39;00m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     timing_save_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msave_path\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mnb\u001b[39m}\u001b[39;00m\u001b[39m_timing.pkl\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/brainaudio/.wfst/lib/python3.9/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ebrahim/data2/brain2text/b2t_25/logits/baseline_rnn_ucd_seeds_1_to_9/neurips_b2t_25_causal_transformer_v4_prob_1_seed_0/logits_test_chunk:1_context:20.npz'"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "import resource\n",
    "import time\n",
    "\n",
    "tracemalloc.start()\n",
    "rss_before = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "rescore_bool = True\n",
    "\n",
    "for fn, lm, nb in zip(folder_name, logits_file_name, nbest_save_path_arr):\n",
    "\n",
    "    logits_all = np.load(f\"{base_path}{fn}/{lm}\")\n",
    "\n",
    "    nbest_save_path = f\"{save_path}{nb}.pkl\"\n",
    "    timing_save_path = f\"{save_path}{nb}_timing.pkl\"\n",
    "\n",
    "    if dataset == \"b2t_25\":\n",
    "        \n",
    "        nbest_augmented_save_path = f\"{save_path}{nb}_augmented\"\n",
    "\n",
    "    nbest_outputs = []\n",
    "    nbest_augmented_outputs = []\n",
    "    trial_lengths_ms = []\n",
    "    wfst_decode_times_ms = []\n",
    "\n",
    "    for trial_idx in range(len(logits_all.keys())):\n",
    "        \n",
    "        if trial_idx % 100 == 0:\n",
    "            \n",
    "            print(f\"Decoding trial {trial_idx}...\")\n",
    "        \n",
    "        logits = logits_all[f'arr_{trial_idx}']\n",
    "\n",
    "        trial_length_ms = logits.shape[0] * ms_per_output\n",
    "        trial_lengths_ms.append(trial_length_ms)\n",
    "            \n",
    "        rearranged_logits = arrange_logits(logits)\n",
    "        \n",
    "        t_start = time.perf_counter()\n",
    "        nbest = lm_decode(\n",
    "                        ngramDecoder,\n",
    "                        rearranged_logits[0],\n",
    "                        blankPenalty=blank_penalty,\n",
    "                        returnNBest=return_n_best,\n",
    "                        rescore=rescore_bool,\n",
    "                    )\n",
    "        t_end = time.perf_counter()\n",
    "        decode_time_ms = (t_end - t_start) * 1000\n",
    "        wfst_decode_times_ms.append(decode_time_ms)\n",
    "\n",
    "        rtf = decode_time_ms / trial_length_ms\n",
    "        if trial_idx % 100 == 0:\n",
    "            print(f\"  Trial {trial_idx}: RTF = {rtf:.4f} (decode={decode_time_ms:.1f}ms, trial_len={trial_length_ms:.1f}ms)\")\n",
    "\n",
    "        if dataset == 'b2t_25':\n",
    "            \n",
    "            nbest_augmented = augment_nbest(nbest, acoustic_scale=acoustic_scale, top_candidates_to_augment=20, score_penalty_percent=0.01)\n",
    "            nbest_augmented_outputs.append(nbest_augmented)\n",
    "            \n",
    "            \n",
    "        nbest_outputs.append(nbest)\n",
    "        \n",
    "        with open(nbest_save_path, 'wb') as f:\n",
    "            pickle.dump(nbest_outputs, f)\n",
    "            \n",
    "        if dataset == 'b2t_25':\n",
    "            with open(nbest_augmented_save_path, 'wb') as f:\n",
    "                pickle.dump(nbest_augmented_outputs, f)\n",
    "\n",
    "    # Save timing data for OPT rescoring RTF computation\n",
    "    with open(timing_save_path, 'wb') as f:\n",
    "        pickle.dump({'trial_lengths_ms': trial_lengths_ms, 'wfst_decode_times_ms': wfst_decode_times_ms}, f)\n",
    "\n",
    "    mean_rtf = np.mean([dt / tl for dt, tl in zip(wfst_decode_times_ms, trial_lengths_ms)])\n",
    "    print(f\"\\nWFST Mean RTF: {mean_rtf:.4f}\")\n",
    "\n",
    "current_ram, peak_ram = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "rss_after = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "print(f\"\\n--- Decoding Memory Usage ---\")\n",
    "print(f\"Peak Python RAM (tracemalloc): {peak_ram / (1024**3):.2f} GB\")\n",
    "print(f\"Peak process RSS:              {rss_after / (1024**2):.2f} GB (delta: {(rss_after - rss_before) / (1024**2):.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ebrahim/data2/brain2text/b2t_24/wfst_outputs//.pkl'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbest_save_path1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wfst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
