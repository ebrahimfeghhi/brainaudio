{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a hacky import since brainaudio requires python 3.12 and the .wfst env requires an older\n",
    "# python version \n",
    "import importlib                                                                                                                                                                                                    \n",
    "import wfst_utils\n",
    "importlib.reload(wfst_utils)\n",
    "from wfst_utils import build_lm_decoder, lm_decode, arrange_logits, _cer_and_wer, augment_nbest\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys                                                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'b2t_24'\n",
    "load_lm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"b2t_25\":\n",
    "    blank_penalty = np.log(90)\n",
    "    acoustic_scale = 0.325\n",
    "    beam = 17\n",
    "    rescore = True\n",
    "    base_path = \"/home/ebrahim/data2/brain2text/b2t_25/logits/baseline_rnn_ucd_seeds_1_to_9/\"\n",
    "    save_path = \"/home/ebrahim/data2/brain2text/b2t_25/wfst_outputs/\"\n",
    "\n",
    "    \n",
    "if dataset == \"b2t_24\":\n",
    "    blank_penalty = np.log(7)\n",
    "    acoustic_scale = 0.5\n",
    "    beam = 18\n",
    "    rescore = True\n",
    "    base_path = \"/home/ebrahim/data2/brain2text/b2t_24/logits/\"\n",
    "    save_path = \"/home/ebrahim/data2/brain2text/b2t_24/wfst_outputs/\"\n",
    "    \n",
    "lmDir = \"/home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test\"\n",
    "nbest_value = 100\n",
    "return_n_best = True\n",
    "ms_per_output = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded LM\n",
      "Peak RSS after LM load: 300.15 GB (delta: 299.96 GB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0218 22:54:30.471004 1299607 brain_speech_decoder.h:52] Reading fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/TLG.fst\n",
      "I0218 22:56:36.498576 1299607 brain_speech_decoder.h:58] Reading lm fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/G.fst\n",
      "I0218 22:57:04.100725 1299607 brain_speech_decoder.h:70] Reading rescore fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/G_no_prune.fst\n",
      "I0218 23:05:22.037317 1299607 brain_speech_decoder.h:81] Reading symbol table /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/words.txt\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "\n",
    "rss_before = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "if load_lm and 'ngramDecoder' not in globals(): \n",
    "    \n",
    "    ngramDecoder = build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=nbest_value,\n",
    "        beam=beam,\n",
    "    )\n",
    "    print(\"loaded LM\")\n",
    "\n",
    "rss_after = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "print(f\"Peak RSS after LM load: {rss_after / (1024**2):.2f} GB (delta: {(rss_after - rss_before) / (1024**2):.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name\n",
    "seeds_list = [0,1,2,3,4,5,6,7,8,9]\n",
    "folder_name = [f\"neurips_b2t_24_chunked_unidirectional_transformer_5to20_sec_seed_{i}\" for i in seeds_list]\n",
    "logits_file_name = [\"logits_test_chunk:1_context:7.5.npz\"] * len(seeds_list)\n",
    "nbest_save_path_arr = [f\"time_masked_transformer_24/seed_{i}_test\" for i in seeds_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding trial 0...\n",
      "  Trial 0: RTF = 0.0376 (decode=153.3ms, trial_len=4080.0ms)\n",
      "Decoding trial 100...\n",
      "  Trial 100: RTF = 0.0154 (decode=51.8ms, trial_len=3360.0ms)\n",
      "Decoding trial 200...\n",
      "  Trial 200: RTF = 0.0293 (decode=163.9ms, trial_len=5600.0ms)\n",
      "Decoding trial 300...\n",
      "  Trial 300: RTF = 0.0056 (decode=19.4ms, trial_len=3440.0ms)\n",
      "Decoding trial 400...\n",
      "  Trial 400: RTF = 0.0779 (decode=305.5ms, trial_len=3920.0ms)\n",
      "Decoding trial 500...\n",
      "  Trial 500: RTF = 0.0188 (decode=102.4ms, trial_len=5440.0ms)\n",
      "Decoding trial 600...\n",
      "  Trial 600: RTF = 0.0088 (decode=33.2ms, trial_len=3760.0ms)\n",
      "Decoding trial 700...\n",
      "  Trial 700: RTF = 0.0175 (decode=92.5ms, trial_len=5280.0ms)\n",
      "Decoding trial 800...\n",
      "  Trial 800: RTF = 0.0096 (decode=59.6ms, trial_len=6240.0ms)\n",
      "\n",
      "WFST Mean RTF: 0.0384\n",
      "Decoding trial 0...\n",
      "  Trial 0: RTF = 0.1158 (decode=472.4ms, trial_len=4080.0ms)\n",
      "Decoding trial 100...\n",
      "  Trial 100: RTF = 0.0146 (decode=49.1ms, trial_len=3360.0ms)\n",
      "Decoding trial 200...\n",
      "  Trial 200: RTF = 0.0222 (decode=124.4ms, trial_len=5600.0ms)\n",
      "Decoding trial 300...\n",
      "  Trial 300: RTF = 0.0044 (decode=15.1ms, trial_len=3440.0ms)\n",
      "Decoding trial 400...\n",
      "  Trial 400: RTF = 0.0623 (decode=244.1ms, trial_len=3920.0ms)\n",
      "Decoding trial 500...\n",
      "  Trial 500: RTF = 0.0117 (decode=63.6ms, trial_len=5440.0ms)\n",
      "Decoding trial 600...\n",
      "  Trial 600: RTF = 0.0086 (decode=32.2ms, trial_len=3760.0ms)\n",
      "Decoding trial 700...\n",
      "  Trial 700: RTF = 0.0118 (decode=62.1ms, trial_len=5280.0ms)\n",
      "Decoding trial 800...\n",
      "  Trial 800: RTF = 0.0077 (decode=47.8ms, trial_len=6240.0ms)\n",
      "\n",
      "WFST Mean RTF: 0.0326\n",
      "Decoding trial 0...\n",
      "  Trial 0: RTF = 0.0855 (decode=348.9ms, trial_len=4080.0ms)\n",
      "Decoding trial 100...\n",
      "  Trial 100: RTF = 0.0141 (decode=47.4ms, trial_len=3360.0ms)\n",
      "Decoding trial 200...\n",
      "  Trial 200: RTF = 0.0418 (decode=234.3ms, trial_len=5600.0ms)\n",
      "Decoding trial 300...\n",
      "  Trial 300: RTF = 0.0054 (decode=18.4ms, trial_len=3440.0ms)\n",
      "Decoding trial 400...\n",
      "  Trial 400: RTF = 0.0329 (decode=128.8ms, trial_len=3920.0ms)\n",
      "Decoding trial 500...\n",
      "  Trial 500: RTF = 0.0146 (decode=79.2ms, trial_len=5440.0ms)\n",
      "Decoding trial 600...\n",
      "  Trial 600: RTF = 0.0134 (decode=50.6ms, trial_len=3760.0ms)\n",
      "Decoding trial 700...\n",
      "  Trial 700: RTF = 0.0114 (decode=60.1ms, trial_len=5280.0ms)\n",
      "Decoding trial 800...\n",
      "  Trial 800: RTF = 0.0081 (decode=50.4ms, trial_len=6240.0ms)\n",
      "\n",
      "WFST Mean RTF: 0.0372\n",
      "Decoding trial 0...\n",
      "  Trial 0: RTF = 0.0578 (decode=235.9ms, trial_len=4080.0ms)\n",
      "Decoding trial 100...\n",
      "  Trial 100: RTF = 0.0134 (decode=45.1ms, trial_len=3360.0ms)\n",
      "Decoding trial 200...\n",
      "  Trial 200: RTF = 0.0280 (decode=156.7ms, trial_len=5600.0ms)\n",
      "Decoding trial 300...\n",
      "  Trial 300: RTF = 0.0046 (decode=15.7ms, trial_len=3440.0ms)\n",
      "Decoding trial 400...\n",
      "  Trial 400: RTF = 0.0500 (decode=196.0ms, trial_len=3920.0ms)\n",
      "Decoding trial 500...\n",
      "  Trial 500: RTF = 0.0175 (decode=95.1ms, trial_len=5440.0ms)\n",
      "Decoding trial 600...\n",
      "  Trial 600: RTF = 0.0134 (decode=50.5ms, trial_len=3760.0ms)\n",
      "Decoding trial 700...\n",
      "  Trial 700: RTF = 0.0204 (decode=107.6ms, trial_len=5280.0ms)\n",
      "Decoding trial 800...\n",
      "  Trial 800: RTF = 0.0080 (decode=50.2ms, trial_len=6240.0ms)\n",
      "\n",
      "WFST Mean RTF: 0.0327\n",
      "Decoding trial 0...\n",
      "  Trial 0: RTF = 0.1456 (decode=594.1ms, trial_len=4080.0ms)\n",
      "Decoding trial 100...\n",
      "  Trial 100: RTF = 0.0160 (decode=53.9ms, trial_len=3360.0ms)\n",
      "Decoding trial 200...\n",
      "  Trial 200: RTF = 0.0228 (decode=127.5ms, trial_len=5600.0ms)\n",
      "Decoding trial 300...\n",
      "  Trial 300: RTF = 0.0057 (decode=19.5ms, trial_len=3440.0ms)\n",
      "Decoding trial 400...\n",
      "  Trial 400: RTF = 0.2477 (decode=971.2ms, trial_len=3920.0ms)\n",
      "Decoding trial 500...\n",
      "  Trial 500: RTF = 0.0129 (decode=70.4ms, trial_len=5440.0ms)\n",
      "Decoding trial 600...\n",
      "  Trial 600: RTF = 0.0077 (decode=28.9ms, trial_len=3760.0ms)\n",
      "Decoding trial 700...\n",
      "  Trial 700: RTF = 0.0260 (decode=137.3ms, trial_len=5280.0ms)\n",
      "Decoding trial 800...\n",
      "  Trial 800: RTF = 0.0097 (decode=60.8ms, trial_len=6240.0ms)\n",
      "\n",
      "WFST Mean RTF: 0.0321\n",
      "\n",
      "--- Decoding Memory Usage ---\n",
      "Peak Python RAM (tracemalloc): 0.01 GB\n",
      "Peak process RSS:              319.00 GB (delta: 0.00 GB)\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "import resource\n",
    "import time\n",
    "\n",
    "tracemalloc.start()\n",
    "rss_before = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "rescore_bool = True\n",
    "\n",
    "for fn, lm, nb in zip(folder_name, logits_file_name, nbest_save_path_arr):\n",
    "\n",
    "    logits_all = np.load(f\"{base_path}{fn}/{lm}\")\n",
    "\n",
    "    nbest_save_path = f\"{save_path}{nb}.pkl\"\n",
    "    timing_save_path = f\"{save_path}{nb}_timing.pkl\"\n",
    "\n",
    "    if dataset == \"b2t_25\":\n",
    "        \n",
    "        nbest_augmented_save_path = f\"{save_path}{nb}_augmented\"\n",
    "\n",
    "    nbest_outputs = []\n",
    "    nbest_augmented_outputs = []\n",
    "    trial_lengths_ms = []\n",
    "    wfst_decode_times_ms = []\n",
    "\n",
    "    for trial_idx in range(len(logits_all.keys())):\n",
    "        \n",
    "        if trial_idx % 100 == 0:\n",
    "            \n",
    "            print(f\"Decoding trial {trial_idx}...\")\n",
    "        \n",
    "        logits = logits_all[f'arr_{trial_idx}']\n",
    "\n",
    "        trial_length_ms = logits.shape[0] * ms_per_output\n",
    "        trial_lengths_ms.append(trial_length_ms)\n",
    "            \n",
    "        rearranged_logits = arrange_logits(logits)\n",
    "        \n",
    "        t_start = time.perf_counter()\n",
    "        nbest = lm_decode(\n",
    "                        ngramDecoder,\n",
    "                        rearranged_logits[0],\n",
    "                        blankPenalty=blank_penalty,\n",
    "                        returnNBest=return_n_best,\n",
    "                        rescore=rescore_bool,\n",
    "                    )\n",
    "        t_end = time.perf_counter()\n",
    "        decode_time_ms = (t_end - t_start) * 1000\n",
    "        wfst_decode_times_ms.append(decode_time_ms)\n",
    "\n",
    "        rtf = decode_time_ms / trial_length_ms\n",
    "        if trial_idx % 100 == 0:\n",
    "            print(f\"  Trial {trial_idx}: RTF = {rtf:.4f} (decode={decode_time_ms:.1f}ms, trial_len={trial_length_ms:.1f}ms)\")\n",
    "\n",
    "        if dataset == 'b2t_25':\n",
    "            \n",
    "            nbest_augmented = augment_nbest(nbest, acoustic_scale=acoustic_scale, top_candidates_to_augment=20, score_penalty_percent=0.01)\n",
    "            nbest_augmented_outputs.append(nbest_augmented)\n",
    "            \n",
    "            \n",
    "        nbest_outputs.append(nbest)\n",
    "        \n",
    "        with open(nbest_save_path, 'wb') as f:\n",
    "            pickle.dump(nbest_outputs, f)\n",
    "            \n",
    "        if dataset == 'b2t_25':\n",
    "            with open(nbest_augmented_save_path, 'wb') as f:\n",
    "                pickle.dump(nbest_augmented_outputs, f)\n",
    "\n",
    "    # Save timing data for OPT rescoring RTF computation\n",
    "    with open(timing_save_path, 'wb') as f:\n",
    "        pickle.dump({'trial_lengths_ms': trial_lengths_ms, 'wfst_decode_times_ms': wfst_decode_times_ms}, f)\n",
    "\n",
    "    mean_rtf = np.mean([dt / tl for dt, tl in zip(wfst_decode_times_ms, trial_lengths_ms)])\n",
    "    print(f\"\\nWFST Mean RTF: {mean_rtf:.4f}\")\n",
    "\n",
    "current_ram, peak_ram = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "rss_after = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "print(f\"\\n--- Decoding Memory Usage ---\")\n",
    "print(f\"Peak Python RAM (tracemalloc): {peak_ram / (1024**3):.2f} GB\")\n",
    "print(f\"Peak process RSS:              {rss_after / (1024**2):.2f} GB (delta: {(rss_after - rss_before) / (1024**2):.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ebrahim/data2/brain2text/b2t_24/wfst_outputs//.pkl'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbest_save_path1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wfst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
