{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a hacky import since brainaudio requires python 3.12 and the .wfst env requires an older\n",
    "# python version \n",
    "from wfst_utils import build_lm_decoder, lm_decode, arrange_logits, _cer_and_wer\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_lm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts_24_cleaned = pd.read_pickle(\"/home/ebrahim/data2/brain2text/b2t_24/transcripts_val_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_penalty = np.log(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded LM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0203 01:51:42.584389 21645 brain_speech_decoder.h:52] Reading fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/TLG.fst\n",
      "I0203 01:53:45.067565 21645 brain_speech_decoder.h:58] Reading lm fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/G.fst\n",
      "I0203 01:54:11.672883 21645 brain_speech_decoder.h:70] Reading rescore fst /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/G_no_prune.fst\n",
      "I0203 02:00:42.793962 21645 brain_speech_decoder.h:81] Reading symbol table /home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test/words.txt\n"
     ]
    }
   ],
   "source": [
    "lmDir = \"/home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test\"\n",
    "acoustic_scale = 0.5 \n",
    "nbest = 100\n",
    "return_n_best = True\n",
    "rescore = True\n",
    "\n",
    "if load_lm and 'ngramDecoder' not in globals(): \n",
    "    \n",
    "    ngramDecoder = build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=nbest,\n",
    "        beam=18\n",
    "    )\n",
    "    print(\"loaded LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "logits_all = np.load(\"/home/ebrahim/data2/brain2text/b2t_24/logits/bidirectional_gru_all/bidirectional_gru_seed_0/logits_test.npz\")\n",
    "print(len(logits_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_indices = np.arange(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding trial 0...\n",
      "Decoding trial 100...\n",
      "Decoding trial 200...\n",
      "Decoding trial 300...\n",
      "Decoding trial 400...\n",
      "Decoding trial 500...\n",
      "Decoding trial 600...\n",
      "Decoding trial 700...\n",
      "Decoding trial 800...\n",
      "Decoding trial 900...\n",
      "Decoding trial 1000...\n",
      "Decoding trial 1100...\n"
     ]
    }
   ],
   "source": [
    "nbest_outputs = []\n",
    "\n",
    "for trial_idx in trial_indices:\n",
    "    \n",
    "    if trial_idx % 100 == 0:\n",
    "        \n",
    "        print(f\"Decoding trial {trial_idx}...\")\n",
    "    \n",
    "    logits = logits_all[f'arr_{trial_idx}']\n",
    "        \n",
    "    rearranged_logits = arrange_logits(logits)\n",
    "    \n",
    "    nbest = lm_decode(\n",
    "                    ngramDecoder,\n",
    "                    rearranged_logits[0],\n",
    "                    blankPenalty=blank_penalty,\n",
    "                    returnNBest=return_n_best,\n",
    "                    rescore=rescore,\n",
    "                )\n",
    "    \n",
    "    nbest_outputs.append(nbest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest_save_path = \"/home/ebrahim/data2/brain2text/b2t_24/model_outputs/bidirectional_gru_test/bidirectional_gru_seed_0_nbest_5gram.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(nbest_save_path, \"wb\") as f:\n",
    "    pickle.dump(nbest_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wfst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
