{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a hacky import since brainaudio requires python 3.12 and the .wfst env requires an older\n",
    "# python version \n",
    "import importlib                                                                                                                                                                                                    \n",
    "import wfst_utils\n",
    "importlib.reload(wfst_utils)\n",
    "from wfst_utils import build_lm_decoder, lm_decode, arrange_logits, _cer_and_wer, augment_nbest\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sys                                                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'b2t_25'\n",
    "load_lm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"b2t_25\":\n",
    "    blank_penalty = np.log(90)\n",
    "    acoustic_scale = 0.325\n",
    "    beam = 17\n",
    "    rescore = True\n",
    "    base_path = \"/home/ebrahim/data2/brain2text/b2t_25/logits/baseline_rnn_ucd_seeds_1_to_9/\"\n",
    "    save_path = \"/home/ebrahim/data2/brain2text/b2t_25/wfst_outputs/\"\n",
    "\n",
    "    \n",
    "if dataset == \"b2t_24\":\n",
    "    blank_penalty = np.log(7)\n",
    "    acoustic_scale = 0.5\n",
    "    beam = 18\n",
    "    rescore = True\n",
    "    base_path = \"/home/ebrahim/data2/brain2text/b2t_24/logits/\"\n",
    "    save_path = \"/home/ebrahim/data2/brain2text/b2t_24/wfst_outputs/\"\n",
    "    \n",
    "lmDir = \"/home/ebrahim/data2/brain2text/lm/speech_5gram/lang_test\"\n",
    "nbest_value = 100\n",
    "return_n_best = True\n",
    "ms_per_output = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "\n",
    "rss_before = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "if load_lm and 'ngramDecoder' not in globals(): \n",
    "    \n",
    "    ngramDecoder = build_lm_decoder(\n",
    "        lmDir,\n",
    "        acoustic_scale=acoustic_scale, #1.2\n",
    "        nbest=nbest_value,\n",
    "        beam=beam,\n",
    "    )\n",
    "    print(\"loaded LM\")\n",
    "\n",
    "rss_after = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "print(f\"Peak RSS after LM load: {rss_after / (1024**2):.2f} GB (delta: {(rss_after - rss_before) / (1024**2):.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder name\n",
    "folder_name = [\"baseline_rnn_ucd_npl_seed_1\"]\n",
    "logits_file_name = [\"logits_test.npz\"]\n",
    "nbest_save_path_arr = [\"pretrained_RNN/seed_1_test_with_mem\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding trial 0...\n",
      "  Trial 0: RTF = 0.0248 (decode=97.4ms, trial_len=3920.0ms)\n",
      "Decoding trial 100...\n",
      "  Trial 100: RTF = 0.0068 (decode=55.5ms, trial_len=8160.0ms)\n",
      "Decoding trial 200...\n",
      "  Trial 200: RTF = 0.0043 (decode=18.3ms, trial_len=4240.0ms)\n",
      "Decoding trial 300...\n",
      "  Trial 300: RTF = 0.0453 (decode=184.6ms, trial_len=4080.0ms)\n",
      "Decoding trial 400...\n",
      "  Trial 400: RTF = 0.0044 (decode=18.1ms, trial_len=4080.0ms)\n",
      "Decoding trial 500...\n",
      "  Trial 500: RTF = 0.0345 (decode=121.6ms, trial_len=3520.0ms)\n",
      "Decoding trial 600...\n",
      "  Trial 600: RTF = 0.0101 (decode=73.5ms, trial_len=7280.0ms)\n",
      "Decoding trial 700...\n",
      "  Trial 700: RTF = 0.0381 (decode=213.5ms, trial_len=5600.0ms)\n",
      "Decoding trial 800...\n",
      "  Trial 800: RTF = 0.0211 (decode=131.9ms, trial_len=6240.0ms)\n",
      "Decoding trial 900...\n",
      "  Trial 900: RTF = 0.0382 (decode=241.2ms, trial_len=6320.0ms)\n",
      "Decoding trial 1000...\n",
      "  Trial 1000: RTF = 0.0169 (decode=120.1ms, trial_len=7120.0ms)\n",
      "Decoding trial 1100...\n",
      "  Trial 1100: RTF = 0.0179 (decode=135.0ms, trial_len=7520.0ms)\n",
      "\n",
      "WFST Mean RTF: 0.0321\n",
      "\n",
      "--- Decoding Memory Usage ---\n",
      "Peak Python RAM (tracemalloc): 0.02 GB\n",
      "Peak process RSS:              322.87 GB (delta: 0.00 GB)\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "import resource\n",
    "import time\n",
    "\n",
    "tracemalloc.start()\n",
    "rss_before = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "rescore_bool = True\n",
    "\n",
    "for fn, lm, nb in zip(folder_name, logits_file_name, nbest_save_path_arr):\n",
    "\n",
    "    logits_all = np.load(f\"{base_path}{fn}/{lm}\")\n",
    "\n",
    "    nbest_save_path = f\"{save_path}{nb}.pkl\"\n",
    "    timing_save_path = f\"{save_path}{nb}_timing.pkl\"\n",
    "\n",
    "    if dataset == \"b2t_25\":\n",
    "        \n",
    "        nbest_augmented_save_path = f\"{save_path}{nb}_augmented\"\n",
    "\n",
    "    nbest_outputs = []\n",
    "    nbest_augmented_outputs = []\n",
    "    trial_lengths_ms = []\n",
    "    wfst_decode_times_ms = []\n",
    "\n",
    "    for trial_idx in range(len(logits_all.keys())):\n",
    "        \n",
    "        if trial_idx % 100 == 0:\n",
    "            \n",
    "            print(f\"Decoding trial {trial_idx}...\")\n",
    "        \n",
    "        logits = logits_all[f'arr_{trial_idx}']\n",
    "\n",
    "        trial_length_ms = logits.shape[0] * ms_per_output\n",
    "        trial_lengths_ms.append(trial_length_ms)\n",
    "            \n",
    "        rearranged_logits = arrange_logits(logits)\n",
    "        \n",
    "        t_start = time.perf_counter()\n",
    "        nbest = lm_decode(\n",
    "                        ngramDecoder,\n",
    "                        rearranged_logits[0],\n",
    "                        blankPenalty=blank_penalty,\n",
    "                        returnNBest=return_n_best,\n",
    "                        rescore=rescore_bool,\n",
    "                    )\n",
    "        t_end = time.perf_counter()\n",
    "        decode_time_ms = (t_end - t_start) * 1000\n",
    "        wfst_decode_times_ms.append(decode_time_ms)\n",
    "\n",
    "        rtf = decode_time_ms / trial_length_ms\n",
    "        if trial_idx % 100 == 0:\n",
    "            print(f\"  Trial {trial_idx}: RTF = {rtf:.4f} (decode={decode_time_ms:.1f}ms, trial_len={trial_length_ms:.1f}ms)\")\n",
    "\n",
    "        if dataset == 'b2t_25':\n",
    "            \n",
    "            nbest_augmented = augment_nbest(nbest, acoustic_scale=acoustic_scale, top_candidates_to_augment=20, score_penalty_percent=0.01)\n",
    "            nbest_augmented_outputs.append(nbest_augmented)\n",
    "            \n",
    "            \n",
    "        nbest_outputs.append(nbest)\n",
    "        \n",
    "        with open(nbest_save_path, 'wb') as f:\n",
    "            pickle.dump(nbest_outputs, f)\n",
    "            \n",
    "        if dataset == 'b2t_25':\n",
    "            with open(nbest_augmented_save_path, 'wb') as f:\n",
    "                pickle.dump(nbest_augmented_outputs, f)\n",
    "\n",
    "    # Save timing data for OPT rescoring RTF computation\n",
    "    with open(timing_save_path, 'wb') as f:\n",
    "        pickle.dump({'trial_lengths_ms': trial_lengths_ms, 'wfst_decode_times_ms': wfst_decode_times_ms}, f)\n",
    "\n",
    "    mean_rtf = np.mean([dt / tl for dt, tl in zip(wfst_decode_times_ms, trial_lengths_ms)])\n",
    "    print(f\"\\nWFST Mean RTF: {mean_rtf:.4f}\")\n",
    "\n",
    "current_ram, peak_ram = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "rss_after = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "\n",
    "print(f\"\\n--- Decoding Memory Usage ---\")\n",
    "print(f\"Peak Python RAM (tracemalloc): {peak_ram / (1024**3):.2f} GB\")\n",
    "print(f\"Peak process RSS:              {rss_after / (1024**2):.2f} GB (delta: {(rss_after - rss_before) / (1024**2):.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ebrahim/data2/brain2text/b2t_24/wfst_outputs//.pkl'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbest_save_path1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wfst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
